{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20581d-f5c4-47a1-8b6e-9289655b0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import torch.nn.functional as F\n",
    "from utils import accuracy, AverageMeter, save_checkpoint, visualize_graph, get_parameters_size\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from net_factory import get_network_fn\n",
    "\n",
    "\n",
    "# dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import DataParallel\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983cbb4-bc52-4e7d-9ebf-a700dd4ba4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch GCN MNIST Training')\n",
    "\n",
    "parser.add_argument('--epochs', default=50, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 64)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--pretrained', default='', type=str, metavar='PATH',\n",
    "                    help='path to pretrained checkpoint (default: none)')\n",
    "parser.add_argument('--gpu', default=0, type=int,\n",
    "                    metavar='N', help='GPU device ID (default: -1)')\n",
    "parser.add_argument('--dataset_dir', default='../../MNIST', type=str, metavar='PATH',\n",
    "                    help='path to dataset (default: ../MNIST)')\n",
    "parser.add_argument('--comment', default='', type=str, metavar='INFO',\n",
    "                    help='Extra description for tensorboard')\n",
    "parser.add_argument('--model', default='gcn', type=str, metavar='NETWORK',\n",
    "                    help='Network to train')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "use_cuda = (args.gpu >= 0) and torch.cuda.is_available()\n",
    "best_prec1 = 0\n",
    "writer = SummaryWriter(comment='_'+args.model+'_'+args.comment)\n",
    "iteration = 0\n",
    "\n",
    "# # from loaddataset import load_data\n",
    "# from loaddataset import load_data\n",
    "\n",
    "# batch_size = 64\n",
    "# train_loader = DataLoader(load_data(training=True), batch_size=batch_size, shuffle=True)  # ,prefetch_factor=2\n",
    "# test_loader = DataLoader(load_data(training=False), batch_size=batch_size, shuffle=True)  # ,prefetch_factor=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdaa3e-43a8-4a65-b846-dbc1f66065e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load model\n",
    "model = get_network_fn(name='gcn2way')#GCNCNN\n",
    "print(model)\n",
    "\n",
    "# Try to visulize the model\n",
    "try:\n",
    "\tvisualize_graph(model, writer, input_size=(1, 3, 128, 128))\n",
    "except:\n",
    "\tprint('\\nNetwork Visualization Failed! But the training procedure continue.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b059e-a572-4e84-b2c8-5f5e17d8f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, models, transforms\n",
    "\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# # Here the size of each output sample is set to 2.\n",
    "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "# model.fc = nn.Linear(num_ftrs, 450)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25b1d92b-24b6-4edb-b68e-fba7bc38aef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from  matplotlib import pyplot as plt\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "# dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import DataParallel\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# read image\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "\n",
    "ms_polyu_path = 'dataset/MS_PolyU/'\n",
    "casia_path = 'dataset/CASIA-Multi-Spectral-PalmprintV1/images/'\n",
    "\n",
    "r_img_path = ms_polyu_path + 'Red_ind/'\n",
    "b_img_path =  ms_polyu_path + 'Blue_ind/'\n",
    "n_img_path =  ms_polyu_path + 'NIR_ind/'\n",
    "g_img_path =  ms_polyu_path + 'Green_ind/'\n",
    "\n",
    "################ DATASET CLASS\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes) \n",
    "    return y[labels] \n",
    "# one_hot_embedding(1, 10)\n",
    "def part_init(istrain=True):\n",
    "    r_list = []\n",
    "    b_list = []\n",
    "    vein_list = []\n",
    "    prints_list = []\n",
    "    labels = []\n",
    "    \n",
    "        # split all data into train, test data\n",
    "    train_ratio = 0.9\n",
    "    train_num = int(500 * train_ratio)\n",
    "    print(\"split train users:\",train_num)\n",
    "    if istrain:\n",
    "        for i in tqdm.tqdm(range(train_num)):\n",
    "            for j in range(12):\n",
    "                r_img = np.array(Image.open(os.path.join(r_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                r_normed = (r_img - r_img.min()) / (r_img.max()-r_img.min())\n",
    "                \n",
    "                g_img = np.array(Image.open(os.path.join(g_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                g_normed = (g_img - g_img.min()) / (g_img.max()-g_img.min())\n",
    "\n",
    "                b_img = np.array(Image.open(os.path.join(b_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                b_normed = (b_img - b_img.min()) / (b_img.max()-b_img.min())\n",
    "\n",
    "                n_img = np.array(Image.open(os.path.join(n_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                r_normed = (n_img - n_img.min()) / (n_img.max()-n_img.min())\n",
    "                \n",
    "                rb = r_normed - b_normed * 0.5\n",
    "                rb =  (rb * 128+128).astype(np.uint8)\n",
    "\n",
    "                imgprint = np.dstack((r_img,g_img,b_img))\n",
    "                imgvein = np.dstack((rb, n_img))\n",
    "                \n",
    "                vein_list.append(imgvein)\n",
    "                prints_list.append(imgprint)\n",
    "                # labels.append(one_hot_embedding(i, train_num))\n",
    "                labels.append(i)\n",
    "    else:\n",
    "        for i in tqdm.tqdm(range(train_num,500)):\n",
    "            for j in range(12):\n",
    "                r_img = np.array(Image.open(os.path.join(r_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                r_normed = (r_img - r_img.min()) / (r_img.max()-r_img.min())\n",
    "                \n",
    "                g_img = np.array(Image.open(os.path.join(g_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                g_normed = (g_img - g_img.min()) / (g_img.max()-g_img.min())\n",
    "\n",
    "                b_img = np.array(Image.open(os.path.join(b_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                b_normed = (b_img - b_img.min()) / (b_img.max()-b_img.min())\n",
    "\n",
    "                n_img = np.array(Image.open(os.path.join(n_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                r_normed = (n_img - n_img.min()) / (n_img.max()-n_img.min())\n",
    "                \n",
    "                rb = r_normed - b_normed * 0.5\n",
    "                rb =  (rb * 128+128).astype(np.uint8)\n",
    "                imgprint = np.dstack((r_img,g_img,b_img))\n",
    "                imgvein = np.dstack((rb, n_img))\n",
    "                \n",
    "                vein_list.append(imgvein)\n",
    "                prints_list.append(imgprint)\n",
    "                # labels.append(one_hot_embedding(i, train_num))\n",
    "                labels.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    # return np.array(r_list), np.array(b_list), np.array(n_list), np.array(labels),np.array(r_list_test), np.array(b_list_test), np.array(n_list_test), np.array(labels_test)\n",
    "    return  vein_list,prints_list, labels\n",
    "\n",
    "# r_list, b_list, n_list, labels,r_list_test, b_list_test, n_list_test, labels_test = part_init()\n",
    "class load_data(Dataset):\n",
    "    \"\"\"Loads the Data.\"\"\"\n",
    "    def __init__(self, training=True):\n",
    "\n",
    "        self.training = training\n",
    "#         r_list, b_list, n_list, labels,r_list_test, b_list_test, n_list_test, labels_test = part_init()\n",
    "        self.transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.RandomAffine(30),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Resize((224, 224)),# if resnet\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                              [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "        self.transform_test = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "#         transforms.Resize((224, 224)),# if resnet\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                              [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "        if self.training:\n",
    "            print('\\n...... Train files loading\\n')\n",
    "            self.vein_list,self.prints_list, self.labels= part_init(istrain=True)\n",
    "            print('\\nTrain files loaded ......\\n')\n",
    "        else:\n",
    "            print('\\n...... Test files loading\\n')\n",
    "            self.vein_list,self.prints_list, self.labels = part_init(istrain=False)\n",
    "            print('\\nTest files loaded ......\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vein_list)\n",
    "\n",
    "         \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.training:\n",
    "            prints_img = self.transform(self.prints_list[idx])\n",
    "            vein_img = self.transform(self.vein_list[idx])\n",
    "        else:\n",
    "            prints_img = self.transform_test(self.prints_list[idx])\n",
    "            vein_img = self.transform_test(self.vein_list[idx])\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        n_img = np.dstack((prints_img[0,:,:],prints_img[1,:,:],prints_img[2,:,:],vein_img[0,:,:],vein_img[1,:,:]))\n",
    "        \n",
    "        return n_img,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33159f71-22b4-4950-9972-b2cfa3d3277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Train files loading\n",
      "\n",
      "split train users: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:34<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train files loaded ......\n",
      "\n",
      "\n",
      "...... Test files loading\n",
      "\n",
      "split train users: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test files loaded ......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(load_data(training=True), batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True,prefetch_factor=8)  # ,prefetch_factor=2\n",
    "test_loader = DataLoader(load_data(training=False), batch_size=batch_size, shuffle=True)  # ,prefetch_factor=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5106d6-538f-49b0-8727-639819292ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, img in tqdm.tqdm(enumerate(train_loader)):\n",
    "    print((img[0].size(), img[1].size()))\n",
    "    break\n",
    "    \n",
    "for _, img in tqdm.tqdm(enumerate(test_loader)):\n",
    "    print((img[0].size(), img[1].size()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b07f76d-3767-4c30-a673-4ade0f99d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(img[0].permute(0, 3, 1, 2).size())\n",
    "# print(img[0].permute(0, 3, 1, 2).double().dtype )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac54206-2374-4eca-89a9-9dedd82149ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b584df4-e536-405f-b2a8-aecca260adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs = model(img[0].permute(0, 3, 1, 2).float())\n",
    "# print(outs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479d25d-f9eb-440c-9754-2563f963c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# optimizer = optim.Adadelta(model.parameters(), lr=args.lr, rho=0.9, eps=1e-06, weight_decay=3e-05)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=3e-05)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=args.momentum, weight_decay=3e-05)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "128280a3-f568-480b-b494-76e70bcc17d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1.47 million float parameters\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 1 [0/5400 (0%)]\tLoss: 0.095312, Accuracy: 96.88, lr: 0.00194\n",
      "Epoch time:20.01s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 2 [0/5400 (0%)]\tLoss: 0.007453, Accuracy: 100.00, lr: 0.00174\n",
      "Epoch time:18.59s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 3 [0/5400 (0%)]\tLoss: 0.033616, Accuracy: 98.44, lr: 0.00174\n",
      "Epoch time:18.81s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 4 [0/5400 (0%)]\tLoss: 0.013299, Accuracy: 100.00, lr: 0.00174\n",
      "Epoch time:19.60s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 5 [0/5400 (0%)]\tLoss: 0.084777, Accuracy: 98.44, lr: 0.00174\n",
      "Epoch time:17.98s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 6 [0/5400 (0%)]\tLoss: 0.019205, Accuracy: 100.00, lr: 0.00174\n",
      "Epoch time:20.49s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 7 [0/5400 (0%)]\tLoss: 0.088551, Accuracy: 98.44, lr: 0.00174\n",
      "Epoch time:19.01s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 8 [0/5400 (0%)]\tLoss: 0.009707, Accuracy: 100.00, lr: 0.00174\n",
      "Epoch time:17.48s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 9 [0/5400 (0%)]\tLoss: 0.025258, Accuracy: 100.00, lr: 0.00174\n",
      "Epoch time:18.40s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 10 [0/5400 (0%)]\tLoss: 0.005606, Accuracy: 100.00, lr: 0.00174\n",
      "Epoch time:18.71s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 11 [0/5400 (0%)]\tLoss: 0.009104, Accuracy: 100.00, lr: 0.00174\n",
      "Epoch time:19.82s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 12 [0/5400 (0%)]\tLoss: 0.049587, Accuracy: 98.44, lr: 0.00157\n",
      "Epoch time:22.39s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 13 [0/5400 (0%)]\tLoss: 0.020223, Accuracy: 98.44, lr: 0.00157\n",
      "Epoch time:22.90s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 14 [0/5400 (0%)]\tLoss: 0.083364, Accuracy: 96.88, lr: 0.00157\n",
      "Epoch time:22.61s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 15 [0/5400 (0%)]\tLoss: 0.069965, Accuracy: 96.88, lr: 0.00157\n",
      "Epoch time:23.99s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 16 [0/5400 (0%)]\tLoss: 0.051466, Accuracy: 98.44, lr: 0.00157\n",
      "Epoch time:23.17s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 17 [0/5400 (0%)]\tLoss: 0.054515, Accuracy: 98.44, lr: 0.00157\n",
      "Epoch time:23.11s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 18 [0/5400 (0%)]\tLoss: 0.089587, Accuracy: 96.88, lr: 0.00157\n",
      "Epoch time:21.21s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 19 [0/5400 (0%)]\tLoss: 0.060828, Accuracy: 98.44, lr: 0.00157\n",
      "Epoch time:23.29s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 20 [0/5400 (0%)]\tLoss: 0.013602, Accuracy: 100.00, lr: 0.00157\n",
      "Epoch time:16.53s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 21 [0/5400 (0%)]\tLoss: 0.061278, Accuracy: 96.88, lr: 0.00157\n",
      "Epoch time:14.48s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 22 [0/5400 (0%)]\tLoss: 0.016777, Accuracy: 100.00, lr: 0.00141\n",
      "Epoch time:14.62s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 23 [0/5400 (0%)]\tLoss: 0.022256, Accuracy: 100.00, lr: 0.00141\n",
      "Epoch time:13.42s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 24 [0/5400 (0%)]\tLoss: 0.019657, Accuracy: 100.00, lr: 0.00141\n",
      "Epoch time:13.54s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 25 [0/5400 (0%)]\tLoss: 0.021414, Accuracy: 100.00, lr: 0.00141\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9736/2576741497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m#     prec1 = test(epoch+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9736/2576741497.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mrbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate the total parameters of the model\n",
    "print('Model size: {:0.2f} million float parameters'.format(get_parameters_size(model)/1e6))\n",
    "\n",
    "if args.pretrained:\n",
    "    if os.path.isfile(args.pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.pretrained))\n",
    "        checkpoint = torch.load(args.pretrained)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.pretrained))\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    global iteration\n",
    "    st = time.time()\n",
    "    for batch_idx, img in enumerate(train_loader):\n",
    "        rbn = img[0].permute(0, 3, 1, 2).to(device, dtype=torch.float)\n",
    "        label = img[1].to(device)\n",
    "        model.train()\n",
    "#         print(rbn.size())\n",
    "        #  r_diff n is vein  RGB is print\n",
    "#         vein = torch.cat([r_diff,n], dim=1)\n",
    "#         pprint = torch.cat([r,b], dim=1)\n",
    "#         inputs = torch.cat([r,b,n], dim=1)\n",
    "        inputs = rbn\n",
    "        iteration += 1\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        prec1, = accuracy(output, label)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.2f}, lr: {:.5f}'.format(\n",
    "                epoch, batch_idx * len(inputs), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), prec1.item(),optimizer.param_groups[0]['lr']))\n",
    "            writer.add_scalar('Loss/Train', loss.item(), iteration)\n",
    "            writer.add_scalar('Accuracy/Train', prec1, iteration)\n",
    "    epoch_time = time.time() - st\n",
    "    print('Epoch time:{:0.2f}s'.format(epoch_time))\n",
    "    scheduler.step()\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    " \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%, lr: {:.2f}%\\n'.format(test_loss.avg, acc.avg))\n",
    "    writer.add_scalar('Loss/Test', test_loss.avg, epoch)\n",
    "    writer.add_scalar('Accuracy/Test', acc.avg, epoch)\n",
    "    return acc.avg\n",
    "\n",
    "for epoch in range(args.start_epoch, 1000):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    train(epoch+1)\n",
    "#     prec1 = test(epoch+1)\n",
    "\n",
    "#     # remember best prec@1 and save checkpoint\n",
    "#     is_best = prec1 > best_prec1\n",
    "#     best_prec1 = max(prec1, best_prec1)\n",
    "#     save_checkpoint({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'state_dict': model.state_dict(),\n",
    "#         'best_prec1': best_prec1,\n",
    "#         'optimizer' : optimizer.state_dict(),\n",
    "#     }, is_best)\n",
    "\n",
    "print('Finished!')\n",
    "print('Best Test Precision@top1:{:.2f}'.format(best_prec1))\n",
    "writer.add_scalar('Best TOP1', best_prec1, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c9a085d-7905-4d95-a92b-dca883df4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Test files loading\n",
      "\n",
      "split train users: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test files loaded ......\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(load_data(training=False), batch_size=batch_size, shuffle=False)  # ,prefetch_factor=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c20120f-d310-4dc6-8b6c-3f00a94f442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([64, 128, 128, 5]), torch.Size([64]))\n",
      "tensor([450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 451, 451,\n",
      "        451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 452, 452, 452, 452,\n",
      "        452, 452, 452, 452, 452, 452, 452, 452, 453, 453, 453, 453, 453, 453,\n",
      "        453, 453, 453, 453, 453, 453, 454, 454, 454, 454, 454, 454, 454, 454,\n",
      "        454, 454, 454, 454, 455, 455, 455, 455])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _, img in tqdm.tqdm(enumerate(test_loader)):\n",
    "    print((img[0].size(), img[1].size()))\n",
    "    break\n",
    "print(img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2253928-e81e-4878-b0a0-09cde7302ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN2way(\n",
      "  (model_vein): Sequential(\n",
      "    (0): GConv(2, 10, kernel_size=(4, 5, 5), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GConv(10, 20, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): GConv(20, 40, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): GConv(40, 80, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (12): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "  )\n",
      "  (model_print): Sequential(\n",
      "    (0): GConv(3, 10, kernel_size=(4, 5, 5), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GConv(10, 20, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): GConv(20, 40, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): GConv(40, 80, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (12): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=160, out_features=1024, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=450, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f8009caf0d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "print(model)\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "##### REGISTER HOOK\n",
    "\n",
    "model.fc1.register_forward_hook(get_features('feats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79f1841c-fd4b-4c4e-b867-77a297778675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATS = []\n",
    "GT = []\n",
    "features = {}\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, img in enumerate(test_loader):\n",
    "            rbn = img[0].permute(0, 3, 1, 2).to(device, dtype=torch.float)\n",
    "            label = img[1].to(device)\n",
    "\n",
    "            output = model(rbn)\n",
    "            FEATS.append(features['feats'].cpu().numpy())\n",
    "            GT.append(img[1].numpy())\n",
    "\n",
    "  \n",
    "    return acc.avg\n",
    "\n",
    "test()\n",
    "##### INSPECT FEATURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "021b1964-473b-4444-b003-4fcf3cd1242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- feats shape: (600, 1024)\n",
      "- GT shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FEATS = np.concatenate(FEATS)\n",
    "GT = np.concatenate(GT)\n",
    "\n",
    "print('- feats shape:', FEATS.shape)\n",
    "print('- GT shape:', GT.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbc60cae-2740-45df-9277-817c10f4fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:11<00:00, 52.85it/s] \n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cossim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "pred_scores = []\n",
    "gt_label = []\n",
    "\n",
    "for i in tqdm.tqdm(range(600)):\n",
    "    for j in range(i+1,600):\n",
    "        # pred_scores.append(final[i,j].detach().cpu().numpy())\n",
    "        pred_scores.append(cossim(FEATS[i,:],FEATS[j,:]))\n",
    "        gt_label.append(i//12 == j//12)\n",
    "        \n",
    "\n",
    "# for i in tqdm.tqdm(range(600)):\n",
    "#         # pred_scores.append(final[i,j].detach().cpu().numpy())\n",
    "#         pred_scores.append(cossim(FEATS[i,:],FEATS[]))\n",
    "#         # gt_label.append(i//12 == j//12)\n",
    "pred_scores = np.array(pred_scores)\n",
    "gt_label = np.array(gt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70fbcf98-18e0-4fda-8bfd-53925629bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Density')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Gen = pred_scores[gt_label]\n",
    "Imp = pred_scores[gt_label==False]\n",
    "Imp = Imp[np.random.permutation(len(Imp))[:len(Gen)]]\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.distplot(Gen,  kde=False, label='Gen')\n",
    "# df =gapminder[gapminder.continent == 'Americas']\n",
    "sns.distplot(Imp,  kde=False,label='Imp')\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Life Expectancy of Two Continents')\n",
    "plt.xlabel('Life Exp (years)')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9673f170-9bc8-499b-a6c2-29209e84ad25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equal error rate is 0.020\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "\"\"\"\n",
    "Python compute equal error rate (eer)\n",
    "ONLY tested on binary classification\n",
    "\n",
    ":param label: ground-truth label, should be a 1-d list or np.array, each element represents the ground-truth label of one sample\n",
    ":param pred: model prediction, should be a 1-d list or np.array, each element represents the model prediction of one sample\n",
    ":param positive_label: the class that is viewed as positive class when computing EER\n",
    ":return: equal error rate (EER)\n",
    "\"\"\"\n",
    "def compute_eer(label, pred, positive_label=1):\n",
    "    # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)\n",
    "    fpr, tpr, threshold = sklearn.metrics.roc_curve(label, pred)#, positive_label\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # the threshold of fnr == fpr\n",
    "    eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "    eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # return the mean of eer from fpr and from fnr\n",
    "    eer = (eer_1 + eer_2) / 2\n",
    "    return eer\n",
    "\n",
    "eer = compute_eer(gt_label, pred_scores)\n",
    "print('The equal error rate is {:.3f}'.format(eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7dd3bd27-046c-42d5-a20d-07a9a4343902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
