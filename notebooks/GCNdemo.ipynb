{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20581d-f5c4-47a1-8b6e-9289655b0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import torch.nn.functional as F\n",
    "from utils import accuracy, AverageMeter, save_checkpoint, visualize_graph, get_parameters_size\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from net_factory import get_network_fn\n",
    "\n",
    "\n",
    "# dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import DataParallel\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983cbb4-bc52-4e7d-9ebf-a700dd4ba4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch GCN MNIST Training')\n",
    "\n",
    "parser.add_argument('--epochs', default=50, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 64)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--pretrained', default='', type=str, metavar='PATH',\n",
    "                    help='path to pretrained checkpoint (default: none)')\n",
    "parser.add_argument('--gpu', default=0, type=int,\n",
    "                    metavar='N', help='GPU device ID (default: -1)')\n",
    "parser.add_argument('--dataset_dir', default='../../MNIST', type=str, metavar='PATH',\n",
    "                    help='path to dataset (default: ../MNIST)')\n",
    "parser.add_argument('--comment', default='', type=str, metavar='INFO',\n",
    "                    help='Extra description for tensorboard')\n",
    "parser.add_argument('--model', default='gcn', type=str, metavar='NETWORK',\n",
    "                    help='Network to train')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "use_cuda = (args.gpu >= 0) and torch.cuda.is_available()\n",
    "best_prec1 = 0\n",
    "writer = SummaryWriter(comment='_'+args.model+'_'+args.comment)\n",
    "iteration = 0\n",
    "\n",
    "# # from loaddataset import load_data\n",
    "# from loaddataset import load_data\n",
    "\n",
    "# batch_size = 64\n",
    "# train_loader = DataLoader(load_data(training=True), batch_size=batch_size, shuffle=True)  # ,prefetch_factor=2\n",
    "# test_loader = DataLoader(load_data(training=False), batch_size=batch_size, shuffle=True)  # ,prefetch_factor=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdaa3e-43a8-4a65-b846-dbc1f66065e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load model\n",
    "model = get_network_fn(name='gcn')#GCNCNN\n",
    "# print(model)\n",
    "\n",
    "# Try to visulize the model\n",
    "try:\n",
    "\tvisualize_graph(model, writer, input_size=(1, 3, 128, 128))\n",
    "except:\n",
    "\tprint('\\nNetwork Visualization Failed! But the training procedure continue.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b059e-a572-4e84-b2c8-5f5e17d8f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, models, transforms\n",
    "\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# # Here the size of each output sample is set to 2.\n",
    "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "# model.fc = nn.Linear(num_ftrs, 450)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f262d-ec72-44bd-90bd-cad5f84cbe49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1d92b-24b6-4edb-b68e-fba7bc38aef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from  matplotlib import pyplot as plt\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "# dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import DataParallel\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# read image\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "\n",
    "ms_polyu_path = 'dataset/MS_PolyU/'\n",
    "casia_path = 'dataset/CASIA-Multi-Spectral-PalmprintV1/images/'\n",
    "\n",
    "r_img_path = ms_polyu_path + 'Red_ind/'\n",
    "b_img_path =  ms_polyu_path + 'Blue_ind/'\n",
    "g_img_path =  ms_polyu_path + 'Green_ind/'\n",
    "n_img_path =  ms_polyu_path + 'NIR_ind/'\n",
    "\n",
    "################ DATASET CLASS\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes) \n",
    "    return y[labels] \n",
    "# one_hot_embedding(1, 10)\n",
    "def part_init(istrain=True):\n",
    "    r_list = []\n",
    "    b_list = []\n",
    "    n_list = []\n",
    "    labels = []\n",
    "    \n",
    "        # split all data into train, test data\n",
    "    train_ratio = 0.9\n",
    "    train_num = int(500 * train_ratio)\n",
    "    print(\"split train users:\",train_num)\n",
    "    if istrain:\n",
    "        for i in tqdm.tqdm(range(train_num)):\n",
    "            for j in range(12):\n",
    "                r_img = np.array(Image.open(os.path.join(r_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "\n",
    "                g_img = np.array(Image.open(os.path.join(g_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                \n",
    "                b_img = np.array(Image.open(os.path.join(b_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "\n",
    "                n_img = np.array(Image.open(os.path.join(n_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                \n",
    "                img = np.dstack((r_img,g_img,n_img))\n",
    "                \n",
    "                n_list.append(img)\n",
    "                # labels.append(one_hot_embedding(i, train_num))\n",
    "                labels.append(i)\n",
    "    else:\n",
    "        for i in tqdm.tqdm(range(train_num,500)):\n",
    "            for j in range(12):\n",
    "                r_img = np.array(Image.open(os.path.join(r_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "\n",
    "                g_img = np.array(Image.open(os.path.join(g_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                \n",
    "                b_img = np.array(Image.open(os.path.join(b_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "\n",
    "                n_img = np.array(Image.open(os.path.join(n_img_path, \"%04d_\"%(i+1)+\"%04d.jpg\"%(j+1))))\n",
    "                \n",
    "                img = np.dstack((r_img,g_img,n_img))\n",
    "                \n",
    "                n_list.append(img)\n",
    "                # labels.append(one_hot_embedding(i, train_num))\n",
    "                labels.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    # return np.array(r_list), np.array(b_list), np.array(n_list), np.array(labels),np.array(r_list_test), np.array(b_list_test), np.array(n_list_test), np.array(labels_test)\n",
    "    return  n_list, labels\n",
    "\n",
    "# r_list, b_list, n_list, labels,r_list_test, b_list_test, n_list_test, labels_test = part_init()\n",
    "class load_data(Dataset):\n",
    "    \"\"\"Loads the Data.\"\"\"\n",
    "    def __init__(self, training=True):\n",
    "\n",
    "        self.training = training\n",
    "#         r_list, b_list, n_list, labels,r_list_test, b_list_test, n_list_test, labels_test = part_init()\n",
    "        self.transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.RandomAffine(30),\n",
    "#         transforms.Resize((224, 224)),# if resnet\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                              [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "        self.transform_test = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Resize((224, 224)),# if resnet\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                              [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "        if self.training:\n",
    "            print('\\n...... Train files loading\\n')\n",
    "            self.n_list, self.labels= part_init(istrain=True)\n",
    "            print('\\nTrain files loaded ......\\n')\n",
    "        else:\n",
    "            print('\\n...... Test files loading\\n')\n",
    "            self.n_list, self.labels = part_init(istrain=False)\n",
    "            print('\\nTest files loaded ......\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.n_list)\n",
    "\n",
    "         \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "#         trans = transforms.Compose([\n",
    "#         transforms.Grayscale(num_output_channels=3),\n",
    "#         transforms.RandomResizedCrop(size=128, scale=(0.8, 1.0)),\n",
    "#         transforms.RandomRotation(degrees=15),\n",
    "#         transforms.CenterCrop(size=128),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                              [0.229, 0.224, 0.225])])\n",
    "        if self.training:\n",
    "            n_img = self.transform(self.n_list[idx])\n",
    "        else:\n",
    "            n_img = self.transform_test(self.n_list[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return n_img,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33159f71-22b4-4950-9972-b2cfa3d3277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(load_data(training=True), batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True,prefetch_factor=8)  # ,prefetch_factor=2\n",
    "# test_loader = DataLoader(load_data(training=False), batch_size=batch_size, shuffle=True)  # ,prefetch_factor=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5106d6-538f-49b0-8727-639819292ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, img in tqdm.tqdm(enumerate(train_loader)):\n",
    "    print((img[0].size(), img[1].size()))\n",
    "    break\n",
    "    \n",
    "# for _, img in tqdm.tqdm(enumerate(test_loader)):\n",
    "#     print((img[0].size(), img[1].size()))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "128280a3-f568-480b-b494-76e70bcc17d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 0.97 million float parameters\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 1 [0/5400 (0%)]\tLoss: 0.242451, Accuracy: 94.92, lr: 0.01000\n",
      "Train Epoch: 1 [2800/5400 (91%)]\tLoss: 0.217546, Accuracy: 95.71, lr: 0.01000\n",
      "Epoch time:10.71s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 2 [0/5400 (0%)]\tLoss: 0.297109, Accuracy: 93.55, lr: 0.01000\n",
      "Train Epoch: 2 [2800/5400 (91%)]\tLoss: 0.261186, Accuracy: 95.00, lr: 0.01000\n",
      "Epoch time:9.30s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 3 [0/5400 (0%)]\tLoss: 0.276405, Accuracy: 95.70, lr: 0.01000\n",
      "Train Epoch: 3 [2800/5400 (91%)]\tLoss: 0.157573, Accuracy: 97.14, lr: 0.01000\n",
      "Epoch time:12.90s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 4 [0/5400 (0%)]\tLoss: 0.281638, Accuracy: 93.95, lr: 0.01000\n",
      "Train Epoch: 4 [2800/5400 (91%)]\tLoss: 0.231794, Accuracy: 96.79, lr: 0.01000\n",
      "Epoch time:13.92s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 5 [0/5400 (0%)]\tLoss: 0.246322, Accuracy: 94.73, lr: 0.01000\n",
      "Train Epoch: 5 [2800/5400 (91%)]\tLoss: 0.277547, Accuracy: 95.00, lr: 0.01000\n",
      "Epoch time:8.97s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 6 [0/5400 (0%)]\tLoss: 0.260196, Accuracy: 95.51, lr: 0.01000\n",
      "Train Epoch: 6 [2800/5400 (91%)]\tLoss: 0.245153, Accuracy: 95.00, lr: 0.01000\n",
      "Epoch time:11.40s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 7 [0/5400 (0%)]\tLoss: 0.328259, Accuracy: 93.16, lr: 0.01000\n",
      "Train Epoch: 7 [2800/5400 (91%)]\tLoss: 0.247870, Accuracy: 95.71, lr: 0.01000\n",
      "Epoch time:12.00s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 8 [0/5400 (0%)]\tLoss: 0.249550, Accuracy: 95.31, lr: 0.01000\n",
      "Train Epoch: 8 [2800/5400 (91%)]\tLoss: 0.239185, Accuracy: 95.71, lr: 0.01000\n",
      "Epoch time:8.12s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 9 [0/5400 (0%)]\tLoss: 0.261517, Accuracy: 94.73, lr: 0.01000\n",
      "Train Epoch: 9 [2800/5400 (91%)]\tLoss: 0.246247, Accuracy: 96.07, lr: 0.01000\n",
      "Epoch time:13.22s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 10 [0/5400 (0%)]\tLoss: 0.220377, Accuracy: 96.68, lr: 0.01000\n",
      "Train Epoch: 10 [2800/5400 (91%)]\tLoss: 0.262166, Accuracy: 93.57, lr: 0.01000\n",
      "Epoch time:11.80s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 11 [0/5400 (0%)]\tLoss: 0.260013, Accuracy: 93.36, lr: 0.00990\n",
      "Train Epoch: 11 [2800/5400 (91%)]\tLoss: 0.225889, Accuracy: 95.71, lr: 0.00990\n",
      "Epoch time:7.68s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 12 [0/5400 (0%)]\tLoss: 0.226960, Accuracy: 95.51, lr: 0.00990\n",
      "Train Epoch: 12 [2800/5400 (91%)]\tLoss: 0.256651, Accuracy: 96.07, lr: 0.00990\n",
      "Epoch time:14.17s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 13 [0/5400 (0%)]\tLoss: 0.252456, Accuracy: 94.73, lr: 0.00990\n",
      "Train Epoch: 13 [2800/5400 (91%)]\tLoss: 0.203721, Accuracy: 96.43, lr: 0.00990\n",
      "Epoch time:11.42s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 14 [0/5400 (0%)]\tLoss: 0.243133, Accuracy: 95.12, lr: 0.00990\n",
      "Train Epoch: 14 [2800/5400 (91%)]\tLoss: 0.200234, Accuracy: 96.43, lr: 0.00990\n",
      "Epoch time:8.48s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 15 [0/5400 (0%)]\tLoss: 0.201585, Accuracy: 96.68, lr: 0.00990\n",
      "Train Epoch: 15 [2800/5400 (91%)]\tLoss: 0.235201, Accuracy: 94.64, lr: 0.00990\n",
      "Epoch time:14.33s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 16 [0/5400 (0%)]\tLoss: 0.182530, Accuracy: 97.66, lr: 0.00990\n",
      "Train Epoch: 16 [2800/5400 (91%)]\tLoss: 0.190994, Accuracy: 96.43, lr: 0.00990\n",
      "Epoch time:11.00s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 17 [0/5400 (0%)]\tLoss: 0.221860, Accuracy: 95.70, lr: 0.00990\n",
      "Train Epoch: 17 [2800/5400 (91%)]\tLoss: 0.224750, Accuracy: 96.07, lr: 0.00990\n",
      "Epoch time:9.39s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 18 [0/5400 (0%)]\tLoss: 0.246059, Accuracy: 95.12, lr: 0.00990\n",
      "Train Epoch: 18 [2800/5400 (91%)]\tLoss: 0.215833, Accuracy: 96.07, lr: 0.00990\n",
      "Epoch time:14.81s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 19 [0/5400 (0%)]\tLoss: 0.207604, Accuracy: 95.70, lr: 0.00990\n",
      "Train Epoch: 19 [2800/5400 (91%)]\tLoss: 0.238646, Accuracy: 95.00, lr: 0.00990\n",
      "Epoch time:11.40s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 20 [0/5400 (0%)]\tLoss: 0.224740, Accuracy: 95.70, lr: 0.00990\n",
      "Train Epoch: 20 [2800/5400 (91%)]\tLoss: 0.219536, Accuracy: 96.07, lr: 0.00990\n",
      "Epoch time:7.99s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 21 [0/5400 (0%)]\tLoss: 0.177849, Accuracy: 96.68, lr: 0.00980\n",
      "Train Epoch: 21 [2800/5400 (91%)]\tLoss: 0.221486, Accuracy: 94.64, lr: 0.00980\n",
      "Epoch time:13.29s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 22 [0/5400 (0%)]\tLoss: 0.180478, Accuracy: 97.46, lr: 0.00980\n",
      "Train Epoch: 22 [2800/5400 (91%)]\tLoss: 0.188409, Accuracy: 96.79, lr: 0.00980\n",
      "Epoch time:10.30s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 23 [0/5400 (0%)]\tLoss: 0.166915, Accuracy: 97.07, lr: 0.00980\n",
      "Train Epoch: 23 [2800/5400 (91%)]\tLoss: 0.208708, Accuracy: 96.43, lr: 0.00980\n",
      "Epoch time:9.20s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 24 [0/5400 (0%)]\tLoss: 0.166115, Accuracy: 96.09, lr: 0.00980\n",
      "Train Epoch: 24 [2800/5400 (91%)]\tLoss: 0.218567, Accuracy: 96.79, lr: 0.00980\n",
      "Epoch time:13.22s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 25 [0/5400 (0%)]\tLoss: 0.181810, Accuracy: 96.48, lr: 0.00980\n",
      "Train Epoch: 25 [2800/5400 (91%)]\tLoss: 0.192805, Accuracy: 96.43, lr: 0.00980\n",
      "Epoch time:8.68s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 26 [0/5400 (0%)]\tLoss: 0.140855, Accuracy: 97.85, lr: 0.00980\n",
      "Train Epoch: 26 [2800/5400 (91%)]\tLoss: 0.180155, Accuracy: 96.79, lr: 0.00980\n",
      "Epoch time:10.79s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 27 [0/5400 (0%)]\tLoss: 0.164415, Accuracy: 95.90, lr: 0.00980\n",
      "Train Epoch: 27 [2800/5400 (91%)]\tLoss: 0.185331, Accuracy: 96.07, lr: 0.00980\n",
      "Epoch time:11.74s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 28 [0/5400 (0%)]\tLoss: 0.157275, Accuracy: 96.88, lr: 0.00980\n",
      "Train Epoch: 28 [2800/5400 (91%)]\tLoss: 0.196724, Accuracy: 95.71, lr: 0.00980\n",
      "Epoch time:7.57s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 29 [0/5400 (0%)]\tLoss: 0.196665, Accuracy: 95.70, lr: 0.00980\n",
      "Train Epoch: 29 [2800/5400 (91%)]\tLoss: 0.163464, Accuracy: 96.43, lr: 0.00980\n",
      "Epoch time:12.83s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 30 [0/5400 (0%)]\tLoss: 0.174876, Accuracy: 96.29, lr: 0.00980\n",
      "Train Epoch: 30 [2800/5400 (91%)]\tLoss: 0.202071, Accuracy: 96.79, lr: 0.00980\n",
      "Epoch time:11.57s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 31 [0/5400 (0%)]\tLoss: 0.173940, Accuracy: 96.68, lr: 0.00970\n",
      "Train Epoch: 31 [2800/5400 (91%)]\tLoss: 0.205881, Accuracy: 95.71, lr: 0.00970\n",
      "Epoch time:8.51s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 32 [0/5400 (0%)]\tLoss: 0.144272, Accuracy: 97.46, lr: 0.00970\n",
      "Train Epoch: 32 [2800/5400 (91%)]\tLoss: 0.215594, Accuracy: 96.43, lr: 0.00970\n",
      "Epoch time:13.98s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 33 [0/5400 (0%)]\tLoss: 0.193182, Accuracy: 96.09, lr: 0.00970\n",
      "Train Epoch: 33 [2800/5400 (91%)]\tLoss: 0.158334, Accuracy: 97.50, lr: 0.00970\n",
      "Epoch time:9.90s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 34 [0/5400 (0%)]\tLoss: 0.193625, Accuracy: 95.31, lr: 0.00970\n",
      "Train Epoch: 34 [2800/5400 (91%)]\tLoss: 0.176205, Accuracy: 97.50, lr: 0.00970\n",
      "Epoch time:9.42s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 35 [0/5400 (0%)]\tLoss: 0.161160, Accuracy: 97.27, lr: 0.00970\n",
      "Train Epoch: 35 [2800/5400 (91%)]\tLoss: 0.226396, Accuracy: 94.64, lr: 0.00970\n",
      "Epoch time:13.09s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 36 [0/5400 (0%)]\tLoss: 0.186233, Accuracy: 96.48, lr: 0.00970\n",
      "Train Epoch: 36 [2800/5400 (91%)]\tLoss: 0.192953, Accuracy: 96.07, lr: 0.00970\n",
      "Epoch time:8.49s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 37 [0/5400 (0%)]\tLoss: 0.180392, Accuracy: 96.29, lr: 0.00970\n",
      "Train Epoch: 37 [2800/5400 (91%)]\tLoss: 0.152850, Accuracy: 96.79, lr: 0.00970\n",
      "Epoch time:12.20s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 38 [0/5400 (0%)]\tLoss: 0.133890, Accuracy: 97.85, lr: 0.00970\n",
      "Train Epoch: 38 [2800/5400 (91%)]\tLoss: 0.157091, Accuracy: 97.86, lr: 0.00970\n",
      "Epoch time:10.81s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 39 [0/5400 (0%)]\tLoss: 0.147732, Accuracy: 97.66, lr: 0.00970\n",
      "Train Epoch: 39 [2800/5400 (91%)]\tLoss: 0.184907, Accuracy: 95.71, lr: 0.00970\n",
      "Epoch time:8.30s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 40 [0/5400 (0%)]\tLoss: 0.181692, Accuracy: 95.90, lr: 0.00970\n",
      "Train Epoch: 40 [2800/5400 (91%)]\tLoss: 0.189341, Accuracy: 95.71, lr: 0.00970\n",
      "Epoch time:12.97s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 41 [0/5400 (0%)]\tLoss: 0.157143, Accuracy: 97.85, lr: 0.00961\n",
      "Train Epoch: 41 [2800/5400 (91%)]\tLoss: 0.141704, Accuracy: 97.50, lr: 0.00961\n",
      "Epoch time:8.63s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 42 [0/5400 (0%)]\tLoss: 0.195930, Accuracy: 94.92, lr: 0.00961\n",
      "Train Epoch: 42 [2800/5400 (91%)]\tLoss: 0.155376, Accuracy: 97.50, lr: 0.00961\n",
      "Epoch time:11.19s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 43 [0/5400 (0%)]\tLoss: 0.160091, Accuracy: 96.88, lr: 0.00961\n",
      "Train Epoch: 43 [2800/5400 (91%)]\tLoss: 0.167630, Accuracy: 97.14, lr: 0.00961\n",
      "Epoch time:13.34s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 44 [0/5400 (0%)]\tLoss: 0.163901, Accuracy: 96.48, lr: 0.00961\n",
      "Train Epoch: 44 [2800/5400 (91%)]\tLoss: 0.168747, Accuracy: 96.79, lr: 0.00961\n",
      "Epoch time:8.66s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 45 [0/5400 (0%)]\tLoss: 0.142117, Accuracy: 97.27, lr: 0.00961\n",
      "Train Epoch: 45 [2800/5400 (91%)]\tLoss: 0.188761, Accuracy: 96.07, lr: 0.00961\n",
      "Epoch time:11.71s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 46 [0/5400 (0%)]\tLoss: 0.159767, Accuracy: 97.46, lr: 0.00961\n",
      "Train Epoch: 46 [2800/5400 (91%)]\tLoss: 0.130268, Accuracy: 97.50, lr: 0.00961\n",
      "Epoch time:11.99s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 47 [0/5400 (0%)]\tLoss: 0.146858, Accuracy: 96.88, lr: 0.00961\n",
      "Train Epoch: 47 [2800/5400 (91%)]\tLoss: 0.145019, Accuracy: 97.14, lr: 0.00961\n",
      "Epoch time:6.71s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 48 [0/5400 (0%)]\tLoss: 0.157444, Accuracy: 96.88, lr: 0.00961\n",
      "Train Epoch: 48 [2800/5400 (91%)]\tLoss: 0.167273, Accuracy: 95.71, lr: 0.00961\n",
      "Epoch time:6.11s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 49 [0/5400 (0%)]\tLoss: 0.130379, Accuracy: 98.05, lr: 0.00961\n",
      "Train Epoch: 49 [2800/5400 (91%)]\tLoss: 0.159737, Accuracy: 97.50, lr: 0.00961\n",
      "Epoch time:6.21s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 50 [0/5400 (0%)]\tLoss: 0.181268, Accuracy: 95.90, lr: 0.00961\n",
      "Train Epoch: 50 [2800/5400 (91%)]\tLoss: 0.118910, Accuracy: 98.93, lr: 0.00961\n",
      "Epoch time:6.52s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 51 [0/5400 (0%)]\tLoss: 0.148351, Accuracy: 96.88, lr: 0.00951\n",
      "Train Epoch: 51 [2800/5400 (91%)]\tLoss: 0.146650, Accuracy: 97.86, lr: 0.00951\n",
      "Epoch time:6.37s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 52 [0/5400 (0%)]\tLoss: 0.149337, Accuracy: 97.46, lr: 0.00951\n",
      "Train Epoch: 52 [2800/5400 (91%)]\tLoss: 0.185017, Accuracy: 95.36, lr: 0.00951\n",
      "Epoch time:6.09s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 53 [0/5400 (0%)]\tLoss: 0.161743, Accuracy: 96.29, lr: 0.00951\n",
      "Train Epoch: 53 [2800/5400 (91%)]\tLoss: 0.144468, Accuracy: 96.79, lr: 0.00951\n",
      "Epoch time:6.49s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 54 [0/5400 (0%)]\tLoss: 0.144589, Accuracy: 97.46, lr: 0.00951\n",
      "Train Epoch: 54 [2800/5400 (91%)]\tLoss: 0.106719, Accuracy: 97.86, lr: 0.00951\n",
      "Epoch time:6.52s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 55 [0/5400 (0%)]\tLoss: 0.146319, Accuracy: 96.88, lr: 0.00951\n",
      "Train Epoch: 55 [2800/5400 (91%)]\tLoss: 0.169411, Accuracy: 96.07, lr: 0.00951\n",
      "Epoch time:6.48s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 56 [0/5400 (0%)]\tLoss: 0.138377, Accuracy: 96.88, lr: 0.00951\n",
      "Train Epoch: 56 [2800/5400 (91%)]\tLoss: 0.148434, Accuracy: 97.86, lr: 0.00951\n",
      "Epoch time:7.09s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 57 [0/5400 (0%)]\tLoss: 0.124503, Accuracy: 98.24, lr: 0.00951\n",
      "Train Epoch: 57 [2800/5400 (91%)]\tLoss: 0.130747, Accuracy: 97.86, lr: 0.00951\n",
      "Epoch time:9.54s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 58 [0/5400 (0%)]\tLoss: 0.131537, Accuracy: 97.85, lr: 0.00951\n",
      "Train Epoch: 58 [2800/5400 (91%)]\tLoss: 0.120427, Accuracy: 98.21, lr: 0.00951\n",
      "Epoch time:6.37s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 59 [0/5400 (0%)]\tLoss: 0.125193, Accuracy: 98.24, lr: 0.00951\n",
      "Train Epoch: 59 [2800/5400 (91%)]\tLoss: 0.166659, Accuracy: 95.36, lr: 0.00951\n",
      "Epoch time:6.43s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 60 [0/5400 (0%)]\tLoss: 0.108008, Accuracy: 98.24, lr: 0.00951\n",
      "Train Epoch: 60 [2800/5400 (91%)]\tLoss: 0.123483, Accuracy: 97.50, lr: 0.00951\n",
      "Epoch time:6.88s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 61 [0/5400 (0%)]\tLoss: 0.139825, Accuracy: 97.07, lr: 0.00941\n",
      "Train Epoch: 61 [2800/5400 (91%)]\tLoss: 0.139209, Accuracy: 97.14, lr: 0.00941\n",
      "Epoch time:6.32s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 62 [0/5400 (0%)]\tLoss: 0.127172, Accuracy: 97.66, lr: 0.00941\n",
      "Train Epoch: 62 [2800/5400 (91%)]\tLoss: 0.099299, Accuracy: 99.29, lr: 0.00941\n",
      "Epoch time:6.49s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 63 [0/5400 (0%)]\tLoss: 0.114736, Accuracy: 98.05, lr: 0.00941\n",
      "Train Epoch: 63 [2800/5400 (91%)]\tLoss: 0.133251, Accuracy: 97.86, lr: 0.00941\n",
      "Epoch time:6.40s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 64 [0/5400 (0%)]\tLoss: 0.144642, Accuracy: 96.48, lr: 0.00941\n",
      "Train Epoch: 64 [2800/5400 (91%)]\tLoss: 0.131150, Accuracy: 97.50, lr: 0.00941\n",
      "Epoch time:6.47s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 65 [0/5400 (0%)]\tLoss: 0.158125, Accuracy: 96.29, lr: 0.00941\n",
      "Train Epoch: 65 [2800/5400 (91%)]\tLoss: 0.125510, Accuracy: 97.86, lr: 0.00941\n",
      "Epoch time:6.40s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 66 [0/5400 (0%)]\tLoss: 0.164786, Accuracy: 96.88, lr: 0.00941\n",
      "Train Epoch: 66 [2800/5400 (91%)]\tLoss: 0.164016, Accuracy: 95.36, lr: 0.00941\n",
      "Epoch time:6.51s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 67 [0/5400 (0%)]\tLoss: 0.090865, Accuracy: 98.83, lr: 0.00941\n",
      "Train Epoch: 67 [2800/5400 (91%)]\tLoss: 0.148488, Accuracy: 97.14, lr: 0.00941\n",
      "Epoch time:6.33s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 68 [0/5400 (0%)]\tLoss: 0.128467, Accuracy: 97.46, lr: 0.00941\n",
      "Train Epoch: 68 [2800/5400 (91%)]\tLoss: 0.105529, Accuracy: 98.21, lr: 0.00941\n",
      "Epoch time:6.39s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 69 [0/5400 (0%)]\tLoss: 0.100817, Accuracy: 98.05, lr: 0.00941\n",
      "Train Epoch: 69 [2800/5400 (91%)]\tLoss: 0.135647, Accuracy: 96.43, lr: 0.00941\n",
      "Epoch time:11.69s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 70 [0/5400 (0%)]\tLoss: 0.120181, Accuracy: 97.07, lr: 0.00941\n",
      "Train Epoch: 70 [2800/5400 (91%)]\tLoss: 0.092182, Accuracy: 97.86, lr: 0.00941\n",
      "Epoch time:7.70s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 71 [0/5400 (0%)]\tLoss: 0.095287, Accuracy: 98.63, lr: 0.00932\n",
      "Train Epoch: 71 [2800/5400 (91%)]\tLoss: 0.151746, Accuracy: 97.86, lr: 0.00932\n",
      "Epoch time:13.77s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 72 [0/5400 (0%)]\tLoss: 0.125710, Accuracy: 98.24, lr: 0.00932\n",
      "Train Epoch: 72 [2800/5400 (91%)]\tLoss: 0.143747, Accuracy: 97.14, lr: 0.00932\n",
      "Epoch time:12.44s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 73 [0/5400 (0%)]\tLoss: 0.127977, Accuracy: 97.46, lr: 0.00932\n",
      "Train Epoch: 73 [2800/5400 (91%)]\tLoss: 0.103066, Accuracy: 98.21, lr: 0.00932\n",
      "Epoch time:7.46s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 74 [0/5400 (0%)]\tLoss: 0.155988, Accuracy: 94.92, lr: 0.00932\n",
      "Train Epoch: 74 [2800/5400 (91%)]\tLoss: 0.086322, Accuracy: 98.21, lr: 0.00932\n",
      "Epoch time:13.93s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 75 [0/5400 (0%)]\tLoss: 0.101962, Accuracy: 98.24, lr: 0.00932\n",
      "Train Epoch: 75 [2800/5400 (91%)]\tLoss: 0.110929, Accuracy: 98.21, lr: 0.00932\n",
      "Epoch time:10.89s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 76 [0/5400 (0%)]\tLoss: 0.116992, Accuracy: 97.46, lr: 0.00932\n",
      "Train Epoch: 76 [2800/5400 (91%)]\tLoss: 0.135206, Accuracy: 97.14, lr: 0.00932\n",
      "Epoch time:8.78s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 77 [0/5400 (0%)]\tLoss: 0.126997, Accuracy: 97.46, lr: 0.00932\n",
      "Train Epoch: 77 [2800/5400 (91%)]\tLoss: 0.130494, Accuracy: 96.79, lr: 0.00932\n",
      "Epoch time:13.93s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 78 [0/5400 (0%)]\tLoss: 0.090578, Accuracy: 98.63, lr: 0.00932\n",
      "Train Epoch: 78 [2800/5400 (91%)]\tLoss: 0.136163, Accuracy: 98.21, lr: 0.00932\n",
      "Epoch time:11.38s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 79 [0/5400 (0%)]\tLoss: 0.118802, Accuracy: 96.88, lr: 0.00932\n",
      "Train Epoch: 79 [2800/5400 (91%)]\tLoss: 0.092105, Accuracy: 98.57, lr: 0.00932\n",
      "Epoch time:7.99s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 80 [0/5400 (0%)]\tLoss: 0.090547, Accuracy: 98.44, lr: 0.00932\n",
      "Train Epoch: 80 [2800/5400 (91%)]\tLoss: 0.103813, Accuracy: 97.86, lr: 0.00932\n",
      "Epoch time:12.90s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 81 [0/5400 (0%)]\tLoss: 0.106120, Accuracy: 98.24, lr: 0.00923\n",
      "Train Epoch: 81 [2800/5400 (91%)]\tLoss: 0.148322, Accuracy: 97.14, lr: 0.00923\n",
      "Epoch time:9.93s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 82 [0/5400 (0%)]\tLoss: 0.128302, Accuracy: 96.68, lr: 0.00923\n",
      "Train Epoch: 82 [2800/5400 (91%)]\tLoss: 0.119749, Accuracy: 98.21, lr: 0.00923\n",
      "Epoch time:10.21s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 83 [0/5400 (0%)]\tLoss: 0.116546, Accuracy: 97.66, lr: 0.00923\n",
      "Train Epoch: 83 [2800/5400 (91%)]\tLoss: 0.117464, Accuracy: 97.50, lr: 0.00923\n",
      "Epoch time:13.51s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 84 [0/5400 (0%)]\tLoss: 0.114671, Accuracy: 97.66, lr: 0.00923\n",
      "Train Epoch: 84 [2800/5400 (91%)]\tLoss: 0.096667, Accuracy: 98.21, lr: 0.00923\n",
      "Epoch time:8.55s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 85 [0/5400 (0%)]\tLoss: 0.097346, Accuracy: 98.24, lr: 0.00923\n",
      "Train Epoch: 85 [2800/5400 (91%)]\tLoss: 0.109441, Accuracy: 97.86, lr: 0.00923\n",
      "Epoch time:11.51s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 86 [0/5400 (0%)]\tLoss: 0.116859, Accuracy: 97.46, lr: 0.00923\n",
      "Train Epoch: 86 [2800/5400 (91%)]\tLoss: 0.090457, Accuracy: 98.93, lr: 0.00923\n",
      "Epoch time:12.82s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 87 [0/5400 (0%)]\tLoss: 0.108501, Accuracy: 97.66, lr: 0.00923\n",
      "Train Epoch: 87 [2800/5400 (91%)]\tLoss: 0.100554, Accuracy: 96.79, lr: 0.00923\n",
      "Epoch time:8.69s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 88 [0/5400 (0%)]\tLoss: 0.121381, Accuracy: 97.85, lr: 0.00923\n",
      "Train Epoch: 88 [2800/5400 (91%)]\tLoss: 0.151345, Accuracy: 96.43, lr: 0.00923\n",
      "Epoch time:11.92s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 89 [0/5400 (0%)]\tLoss: 0.086264, Accuracy: 98.24, lr: 0.00923\n",
      "Train Epoch: 89 [2800/5400 (91%)]\tLoss: 0.094068, Accuracy: 99.29, lr: 0.00923\n",
      "Epoch time:11.91s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 90 [0/5400 (0%)]\tLoss: 0.100819, Accuracy: 98.44, lr: 0.00923\n",
      "Train Epoch: 90 [2800/5400 (91%)]\tLoss: 0.142415, Accuracy: 95.71, lr: 0.00923\n",
      "Epoch time:7.47s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 91 [0/5400 (0%)]\tLoss: 0.112037, Accuracy: 98.24, lr: 0.00914\n",
      "Train Epoch: 91 [2800/5400 (91%)]\tLoss: 0.107421, Accuracy: 97.86, lr: 0.00914\n",
      "Epoch time:14.30s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 92 [0/5400 (0%)]\tLoss: 0.079546, Accuracy: 98.83, lr: 0.00914\n",
      "Train Epoch: 92 [2800/5400 (91%)]\tLoss: 0.116115, Accuracy: 97.86, lr: 0.00914\n",
      "Epoch time:11.11s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 93 [0/5400 (0%)]\tLoss: 0.095067, Accuracy: 97.85, lr: 0.00914\n",
      "Train Epoch: 93 [2800/5400 (91%)]\tLoss: 0.097037, Accuracy: 98.57, lr: 0.00914\n",
      "Epoch time:8.59s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 94 [0/5400 (0%)]\tLoss: 0.106529, Accuracy: 97.27, lr: 0.00914\n",
      "Train Epoch: 94 [2800/5400 (91%)]\tLoss: 0.106779, Accuracy: 97.86, lr: 0.00914\n",
      "Epoch time:13.55s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 95 [0/5400 (0%)]\tLoss: 0.079418, Accuracy: 98.83, lr: 0.00914\n",
      "Train Epoch: 95 [2800/5400 (91%)]\tLoss: 0.103140, Accuracy: 97.86, lr: 0.00914\n",
      "Epoch time:10.06s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 96 [0/5400 (0%)]\tLoss: 0.104216, Accuracy: 97.66, lr: 0.00914\n",
      "Train Epoch: 96 [2800/5400 (91%)]\tLoss: 0.098920, Accuracy: 97.86, lr: 0.00914\n",
      "Epoch time:9.70s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 97 [0/5400 (0%)]\tLoss: 0.128381, Accuracy: 96.88, lr: 0.00914\n",
      "Train Epoch: 97 [2800/5400 (91%)]\tLoss: 0.104236, Accuracy: 97.50, lr: 0.00914\n",
      "Epoch time:13.91s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 98 [0/5400 (0%)]\tLoss: 0.094234, Accuracy: 98.24, lr: 0.00914\n",
      "Train Epoch: 98 [2800/5400 (91%)]\tLoss: 0.116543, Accuracy: 97.50, lr: 0.00914\n",
      "Epoch time:8.80s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 99 [0/5400 (0%)]\tLoss: 0.109219, Accuracy: 97.85, lr: 0.00914\n",
      "Train Epoch: 99 [2800/5400 (91%)]\tLoss: 0.145470, Accuracy: 98.21, lr: 0.00914\n",
      "Epoch time:11.47s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 100 [0/5400 (0%)]\tLoss: 0.100735, Accuracy: 98.44, lr: 0.00914\n",
      "Train Epoch: 100 [2800/5400 (91%)]\tLoss: 0.110080, Accuracy: 98.21, lr: 0.00914\n",
      "Epoch time:13.96s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 101 [0/5400 (0%)]\tLoss: 0.094026, Accuracy: 98.83, lr: 0.00904\n",
      "Train Epoch: 101 [2800/5400 (91%)]\tLoss: 0.124870, Accuracy: 97.14, lr: 0.00904\n",
      "Epoch time:10.15s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 102 [0/5400 (0%)]\tLoss: 0.078917, Accuracy: 98.63, lr: 0.00904\n",
      "Train Epoch: 102 [2800/5400 (91%)]\tLoss: 0.096221, Accuracy: 98.21, lr: 0.00904\n",
      "Epoch time:9.40s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 103 [0/5400 (0%)]\tLoss: 0.090168, Accuracy: 98.24, lr: 0.00904\n",
      "Train Epoch: 103 [2800/5400 (91%)]\tLoss: 0.125249, Accuracy: 97.14, lr: 0.00904\n",
      "Epoch time:12.75s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 104 [0/5400 (0%)]\tLoss: 0.109134, Accuracy: 97.27, lr: 0.00904\n",
      "Train Epoch: 104 [2800/5400 (91%)]\tLoss: 0.101930, Accuracy: 97.86, lr: 0.00904\n",
      "Epoch time:8.06s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 105 [0/5400 (0%)]\tLoss: 0.112840, Accuracy: 97.85, lr: 0.00904\n",
      "Train Epoch: 105 [2800/5400 (91%)]\tLoss: 0.104772, Accuracy: 97.14, lr: 0.00904\n",
      "Epoch time:12.44s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 106 [0/5400 (0%)]\tLoss: 0.112670, Accuracy: 97.46, lr: 0.00904\n",
      "Train Epoch: 106 [2800/5400 (91%)]\tLoss: 0.108972, Accuracy: 98.57, lr: 0.00904\n",
      "Epoch time:11.47s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 107 [0/5400 (0%)]\tLoss: 0.106591, Accuracy: 97.85, lr: 0.00904\n",
      "Train Epoch: 107 [2800/5400 (91%)]\tLoss: 0.098577, Accuracy: 98.57, lr: 0.00904\n",
      "Epoch time:7.89s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 108 [0/5400 (0%)]\tLoss: 0.118278, Accuracy: 97.27, lr: 0.00904\n",
      "Train Epoch: 108 [2800/5400 (91%)]\tLoss: 0.139274, Accuracy: 97.50, lr: 0.00904\n",
      "Epoch time:13.20s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 109 [0/5400 (0%)]\tLoss: 0.070413, Accuracy: 99.41, lr: 0.00904\n",
      "Train Epoch: 109 [2800/5400 (91%)]\tLoss: 0.110937, Accuracy: 98.21, lr: 0.00904\n",
      "Epoch time:11.00s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 110 [0/5400 (0%)]\tLoss: 0.102253, Accuracy: 97.85, lr: 0.00904\n",
      "Train Epoch: 110 [2800/5400 (91%)]\tLoss: 0.062834, Accuracy: 99.29, lr: 0.00904\n",
      "Epoch time:8.39s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 111 [0/5400 (0%)]\tLoss: 0.069291, Accuracy: 99.02, lr: 0.00895\n",
      "Train Epoch: 111 [2800/5400 (91%)]\tLoss: 0.138240, Accuracy: 97.14, lr: 0.00895\n",
      "Epoch time:13.43s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 112 [0/5400 (0%)]\tLoss: 0.090304, Accuracy: 98.63, lr: 0.00895\n",
      "Train Epoch: 112 [2800/5400 (91%)]\tLoss: 0.138651, Accuracy: 97.86, lr: 0.00895\n",
      "Epoch time:9.05s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 113 [0/5400 (0%)]\tLoss: 0.071057, Accuracy: 98.83, lr: 0.00895\n",
      "Train Epoch: 113 [2800/5400 (91%)]\tLoss: 0.069707, Accuracy: 99.29, lr: 0.00895\n",
      "Epoch time:13.11s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 114 [0/5400 (0%)]\tLoss: 0.086935, Accuracy: 98.44, lr: 0.00895\n",
      "Train Epoch: 114 [2800/5400 (91%)]\tLoss: 0.096156, Accuracy: 98.21, lr: 0.00895\n",
      "Epoch time:15.83s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 115 [0/5400 (0%)]\tLoss: 0.073457, Accuracy: 98.63, lr: 0.00895\n",
      "Train Epoch: 115 [2800/5400 (91%)]\tLoss: 0.096106, Accuracy: 96.79, lr: 0.00895\n",
      "Epoch time:14.56s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 116 [0/5400 (0%)]\tLoss: 0.075058, Accuracy: 98.24, lr: 0.00895\n",
      "Train Epoch: 116 [2800/5400 (91%)]\tLoss: 0.074532, Accuracy: 98.57, lr: 0.00895\n",
      "Epoch time:9.30s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 117 [0/5400 (0%)]\tLoss: 0.106417, Accuracy: 98.05, lr: 0.00895\n",
      "Train Epoch: 117 [2800/5400 (91%)]\tLoss: 0.069538, Accuracy: 98.93, lr: 0.00895\n",
      "Epoch time:12.31s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 118 [0/5400 (0%)]\tLoss: 0.099858, Accuracy: 97.85, lr: 0.00895\n",
      "Train Epoch: 118 [2800/5400 (91%)]\tLoss: 0.091217, Accuracy: 98.21, lr: 0.00895\n",
      "Epoch time:14.50s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 119 [0/5400 (0%)]\tLoss: 0.125464, Accuracy: 97.07, lr: 0.00895\n",
      "Train Epoch: 119 [2800/5400 (91%)]\tLoss: 0.067856, Accuracy: 99.29, lr: 0.00895\n",
      "Epoch time:10.99s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 120 [0/5400 (0%)]\tLoss: 0.075911, Accuracy: 98.83, lr: 0.00895\n",
      "Train Epoch: 120 [2800/5400 (91%)]\tLoss: 0.066784, Accuracy: 98.21, lr: 0.00895\n",
      "Epoch time:9.00s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 121 [0/5400 (0%)]\tLoss: 0.079744, Accuracy: 98.24, lr: 0.00886\n",
      "Train Epoch: 121 [2800/5400 (91%)]\tLoss: 0.097258, Accuracy: 97.50, lr: 0.00886\n",
      "Epoch time:15.83s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 122 [0/5400 (0%)]\tLoss: 0.082200, Accuracy: 98.83, lr: 0.00886\n",
      "Train Epoch: 122 [2800/5400 (91%)]\tLoss: 0.149138, Accuracy: 97.14, lr: 0.00886\n",
      "Epoch time:11.36s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 123 [0/5400 (0%)]\tLoss: 0.107489, Accuracy: 97.66, lr: 0.00886\n",
      "Train Epoch: 123 [2800/5400 (91%)]\tLoss: 0.093886, Accuracy: 97.86, lr: 0.00886\n",
      "Epoch time:11.22s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 124 [0/5400 (0%)]\tLoss: 0.089950, Accuracy: 97.85, lr: 0.00886\n",
      "Train Epoch: 124 [2800/5400 (91%)]\tLoss: 0.077949, Accuracy: 98.57, lr: 0.00886\n",
      "Epoch time:16.38s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 125 [0/5400 (0%)]\tLoss: 0.117815, Accuracy: 97.85, lr: 0.00886\n",
      "Train Epoch: 125 [2800/5400 (91%)]\tLoss: 0.070015, Accuracy: 99.64, lr: 0.00886\n",
      "Epoch time:13.61s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 126 [0/5400 (0%)]\tLoss: 0.088110, Accuracy: 98.83, lr: 0.00886\n",
      "Train Epoch: 126 [2800/5400 (91%)]\tLoss: 0.059817, Accuracy: 98.93, lr: 0.00886\n",
      "Epoch time:9.10s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 127 [0/5400 (0%)]\tLoss: 0.091931, Accuracy: 98.24, lr: 0.00886\n",
      "Train Epoch: 127 [2800/5400 (91%)]\tLoss: 0.128770, Accuracy: 97.50, lr: 0.00886\n",
      "Epoch time:15.09s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 128 [0/5400 (0%)]\tLoss: 0.072659, Accuracy: 98.24, lr: 0.00886\n",
      "Train Epoch: 128 [2800/5400 (91%)]\tLoss: 0.091526, Accuracy: 98.21, lr: 0.00886\n",
      "Epoch time:14.69s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 129 [0/5400 (0%)]\tLoss: 0.089585, Accuracy: 98.24, lr: 0.00886\n",
      "Train Epoch: 129 [2800/5400 (91%)]\tLoss: 0.087911, Accuracy: 98.21, lr: 0.00886\n",
      "Epoch time:9.22s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 130 [0/5400 (0%)]\tLoss: 0.088343, Accuracy: 98.44, lr: 0.00886\n",
      "Train Epoch: 130 [2800/5400 (91%)]\tLoss: 0.083326, Accuracy: 98.57, lr: 0.00886\n",
      "Epoch time:14.12s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 131 [0/5400 (0%)]\tLoss: 0.073333, Accuracy: 99.41, lr: 0.00878\n",
      "Train Epoch: 131 [2800/5400 (91%)]\tLoss: 0.122170, Accuracy: 97.86, lr: 0.00878\n",
      "Epoch time:14.77s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 132 [0/5400 (0%)]\tLoss: 0.077026, Accuracy: 98.83, lr: 0.00878\n",
      "Train Epoch: 132 [2800/5400 (91%)]\tLoss: 0.098265, Accuracy: 97.86, lr: 0.00878\n",
      "Epoch time:9.38s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 133 [0/5400 (0%)]\tLoss: 0.085103, Accuracy: 97.85, lr: 0.00878\n",
      "Train Epoch: 133 [2800/5400 (91%)]\tLoss: 0.090979, Accuracy: 97.50, lr: 0.00878\n",
      "Epoch time:13.75s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 134 [0/5400 (0%)]\tLoss: 0.080662, Accuracy: 98.24, lr: 0.00878\n",
      "Train Epoch: 134 [2800/5400 (91%)]\tLoss: 0.055694, Accuracy: 99.29, lr: 0.00878\n",
      "Epoch time:14.80s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 135 [0/5400 (0%)]\tLoss: 0.095400, Accuracy: 97.46, lr: 0.00878\n",
      "Train Epoch: 135 [2800/5400 (91%)]\tLoss: 0.122872, Accuracy: 98.21, lr: 0.00878\n",
      "Epoch time:9.67s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 136 [0/5400 (0%)]\tLoss: 0.093375, Accuracy: 98.44, lr: 0.00878\n",
      "Train Epoch: 136 [2800/5400 (91%)]\tLoss: 0.067718, Accuracy: 98.93, lr: 0.00878\n",
      "Epoch time:13.61s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 137 [0/5400 (0%)]\tLoss: 0.054694, Accuracy: 99.41, lr: 0.00878\n",
      "Train Epoch: 137 [2800/5400 (91%)]\tLoss: 0.049177, Accuracy: 99.29, lr: 0.00878\n",
      "Epoch time:16.01s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 138 [0/5400 (0%)]\tLoss: 0.088569, Accuracy: 98.05, lr: 0.00878\n",
      "Train Epoch: 138 [2800/5400 (91%)]\tLoss: 0.102889, Accuracy: 98.21, lr: 0.00878\n",
      "Epoch time:9.87s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 139 [0/5400 (0%)]\tLoss: 0.088367, Accuracy: 97.66, lr: 0.00878\n",
      "Train Epoch: 139 [2800/5400 (91%)]\tLoss: 0.118125, Accuracy: 97.14, lr: 0.00878\n",
      "Epoch time:11.43s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 140 [0/5400 (0%)]\tLoss: 0.083298, Accuracy: 98.24, lr: 0.00878\n",
      "Train Epoch: 140 [2800/5400 (91%)]\tLoss: 0.071567, Accuracy: 98.57, lr: 0.00878\n",
      "Epoch time:14.56s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 141 [0/5400 (0%)]\tLoss: 0.099996, Accuracy: 98.05, lr: 0.00869\n",
      "Train Epoch: 141 [2800/5400 (91%)]\tLoss: 0.099349, Accuracy: 98.21, lr: 0.00869\n",
      "Epoch time:10.73s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 142 [0/5400 (0%)]\tLoss: 0.075238, Accuracy: 98.44, lr: 0.00869\n",
      "Train Epoch: 142 [2800/5400 (91%)]\tLoss: 0.095094, Accuracy: 97.50, lr: 0.00869\n",
      "Epoch time:9.68s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 143 [0/5400 (0%)]\tLoss: 0.083429, Accuracy: 98.05, lr: 0.00869\n",
      "Train Epoch: 143 [2800/5400 (91%)]\tLoss: 0.044592, Accuracy: 99.64, lr: 0.00869\n",
      "Epoch time:13.91s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 144 [0/5400 (0%)]\tLoss: 0.066981, Accuracy: 98.44, lr: 0.00869\n",
      "Train Epoch: 144 [2800/5400 (91%)]\tLoss: 0.080579, Accuracy: 97.14, lr: 0.00869\n",
      "Epoch time:13.22s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 145 [0/5400 (0%)]\tLoss: 0.071573, Accuracy: 98.83, lr: 0.00869\n",
      "Train Epoch: 145 [2800/5400 (91%)]\tLoss: 0.094069, Accuracy: 98.21, lr: 0.00869\n",
      "Epoch time:8.59s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 146 [0/5400 (0%)]\tLoss: 0.048452, Accuracy: 99.61, lr: 0.00869\n",
      "Train Epoch: 146 [2800/5400 (91%)]\tLoss: 0.072419, Accuracy: 98.21, lr: 0.00869\n",
      "Epoch time:11.87s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 147 [0/5400 (0%)]\tLoss: 0.075603, Accuracy: 98.63, lr: 0.00869\n",
      "Train Epoch: 147 [2800/5400 (91%)]\tLoss: 0.079976, Accuracy: 99.29, lr: 0.00869\n",
      "Epoch time:13.92s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 148 [0/5400 (0%)]\tLoss: 0.052411, Accuracy: 99.61, lr: 0.00869\n",
      "Train Epoch: 148 [2800/5400 (91%)]\tLoss: 0.076126, Accuracy: 99.29, lr: 0.00869\n",
      "Epoch time:8.90s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 149 [0/5400 (0%)]\tLoss: 0.088416, Accuracy: 98.63, lr: 0.00869\n",
      "Train Epoch: 149 [2800/5400 (91%)]\tLoss: 0.096963, Accuracy: 97.86, lr: 0.00869\n",
      "Epoch time:12.10s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 150 [0/5400 (0%)]\tLoss: 0.067990, Accuracy: 98.24, lr: 0.00869\n",
      "Train Epoch: 150 [2800/5400 (91%)]\tLoss: 0.098583, Accuracy: 96.79, lr: 0.00869\n",
      "Epoch time:14.10s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 151 [0/5400 (0%)]\tLoss: 0.063700, Accuracy: 99.22, lr: 0.00860\n",
      "Train Epoch: 151 [2800/5400 (91%)]\tLoss: 0.089381, Accuracy: 98.21, lr: 0.00860\n",
      "Epoch time:9.50s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 152 [0/5400 (0%)]\tLoss: 0.073800, Accuracy: 98.63, lr: 0.00860\n",
      "Train Epoch: 152 [2800/5400 (91%)]\tLoss: 0.071353, Accuracy: 98.57, lr: 0.00860\n",
      "Epoch time:9.71s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 153 [0/5400 (0%)]\tLoss: 0.061794, Accuracy: 98.63, lr: 0.00860\n",
      "Train Epoch: 153 [2800/5400 (91%)]\tLoss: 0.057100, Accuracy: 99.64, lr: 0.00860\n",
      "Epoch time:6.40s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 154 [0/5400 (0%)]\tLoss: 0.089703, Accuracy: 98.44, lr: 0.00860\n",
      "Train Epoch: 154 [2800/5400 (91%)]\tLoss: 0.080630, Accuracy: 98.21, lr: 0.00860\n",
      "Epoch time:6.48s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 155 [0/5400 (0%)]\tLoss: 0.085932, Accuracy: 98.63, lr: 0.00860\n",
      "Train Epoch: 155 [2800/5400 (91%)]\tLoss: 0.077471, Accuracy: 98.21, lr: 0.00860\n",
      "Epoch time:6.51s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 156 [0/5400 (0%)]\tLoss: 0.074365, Accuracy: 98.44, lr: 0.00860\n",
      "Train Epoch: 156 [2800/5400 (91%)]\tLoss: 0.068702, Accuracy: 98.21, lr: 0.00860\n",
      "Epoch time:6.70s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 157 [0/5400 (0%)]\tLoss: 0.050391, Accuracy: 99.22, lr: 0.00860\n",
      "Train Epoch: 157 [2800/5400 (91%)]\tLoss: 0.101703, Accuracy: 97.50, lr: 0.00860\n",
      "Epoch time:14.82s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 158 [0/5400 (0%)]\tLoss: 0.074775, Accuracy: 98.44, lr: 0.00860\n",
      "Train Epoch: 158 [2800/5400 (91%)]\tLoss: 0.073762, Accuracy: 99.29, lr: 0.00860\n",
      "Epoch time:6.70s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 159 [0/5400 (0%)]\tLoss: 0.101105, Accuracy: 97.66, lr: 0.00860\n",
      "Train Epoch: 159 [2800/5400 (91%)]\tLoss: 0.050404, Accuracy: 99.29, lr: 0.00860\n",
      "Epoch time:6.66s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 160 [0/5400 (0%)]\tLoss: 0.072926, Accuracy: 98.44, lr: 0.00860\n",
      "Train Epoch: 160 [2800/5400 (91%)]\tLoss: 0.091681, Accuracy: 97.14, lr: 0.00860\n",
      "Epoch time:6.66s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 161 [0/5400 (0%)]\tLoss: 0.088101, Accuracy: 97.46, lr: 0.00851\n",
      "Train Epoch: 161 [2800/5400 (91%)]\tLoss: 0.089589, Accuracy: 97.86, lr: 0.00851\n",
      "Epoch time:6.96s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 162 [0/5400 (0%)]\tLoss: 0.066214, Accuracy: 99.22, lr: 0.00851\n",
      "Train Epoch: 162 [2800/5400 (91%)]\tLoss: 0.042368, Accuracy: 99.29, lr: 0.00851\n",
      "Epoch time:6.72s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 163 [0/5400 (0%)]\tLoss: 0.072842, Accuracy: 98.05, lr: 0.00851\n",
      "Train Epoch: 163 [2800/5400 (91%)]\tLoss: 0.054356, Accuracy: 99.29, lr: 0.00851\n",
      "Epoch time:6.21s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 164 [0/5400 (0%)]\tLoss: 0.073330, Accuracy: 98.63, lr: 0.00851\n",
      "Train Epoch: 164 [2800/5400 (91%)]\tLoss: 0.053867, Accuracy: 99.29, lr: 0.00851\n",
      "Epoch time:6.79s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 165 [0/5400 (0%)]\tLoss: 0.095275, Accuracy: 98.44, lr: 0.00851\n",
      "Train Epoch: 165 [2800/5400 (91%)]\tLoss: 0.053639, Accuracy: 99.64, lr: 0.00851\n",
      "Epoch time:6.86s\n",
      "------------------------------------------------------------------------\n",
      "Train Epoch: 166 [0/5400 (0%)]\tLoss: 0.053999, Accuracy: 99.41, lr: 0.00851\n",
      "Train Epoch: 166 [2800/5400 (91%)]\tLoss: 0.104083, Accuracy: 97.50, lr: 0.00851\n",
      "Epoch time:6.60s\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27183/2807830342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;31m#     prec1 = test(epoch+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27183/2807830342.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mrbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# optimizer = optim.Adadelta(model.parameters(), lr=args.lr, rho=0.9, eps=1e-06, weight_decay=3e-05)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=3e-05)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=3e-05)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.99)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Calculate the total parameters of the model\n",
    "print('Model size: {:0.2f} million float parameters'.format(get_parameters_size(model)/1e6))\n",
    "\n",
    "if args.pretrained:\n",
    "    if os.path.isfile(args.pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.pretrained))\n",
    "        checkpoint = torch.load(args.pretrained)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.pretrained))\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    global iteration\n",
    "    st = time.time()\n",
    "    for batch_idx, img in enumerate(train_loader):\n",
    "        rbn = img[0].to(device, dtype=torch.float)\n",
    "        label = img[1].to(device)\n",
    "        alpha = 0.5  #1 is a scaling factor\n",
    "        model.train()\n",
    "#         print(rbn.size())\n",
    "        #  r_diff n is vein  RGB is print\n",
    "#         vein = torch.cat([r_diff,n], dim=1)\n",
    "#         pprint = torch.cat([r,b], dim=1)\n",
    "#         inputs = torch.cat([r,b,n], dim=1)\n",
    "        inputs = rbn\n",
    "        iteration += 1\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        prec1, = accuracy(output, label)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.print_freq == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.2f}, lr: {:.5f}'.format(\n",
    "                epoch, batch_idx * len(inputs), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), prec1.item(),optimizer.param_groups[0]['lr']))\n",
    "            writer.add_scalar('Loss/Train', loss.item(), iteration)\n",
    "            writer.add_scalar('Accuracy/Train', prec1, iteration)\n",
    "    epoch_time = time.time() - st\n",
    "    print('Epoch time:{:0.2f}s'.format(epoch_time))\n",
    "    scheduler.step()\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    " \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(test_loss.avg, acc.avg))\n",
    "    writer.add_scalar('Loss/Test', test_loss.avg, epoch)\n",
    "    writer.add_scalar('Accuracy/Test', acc.avg, epoch)\n",
    "    return acc.avg\n",
    "\n",
    "for epoch in range(args.start_epoch, 1000):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    train(epoch+1)\n",
    "#     prec1 = test(epoch+1)\n",
    "\n",
    "#     # remember best prec@1 and save checkpoint\n",
    "#     is_best = prec1 > best_prec1\n",
    "#     best_prec1 = max(prec1, best_prec1)\n",
    "#     save_checkpoint({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'state_dict': model.state_dict(),\n",
    "#         'best_prec1': best_prec1,\n",
    "#         'optimizer' : optimizer.state_dict(),\n",
    "#     }, is_best)\n",
    "\n",
    "print('Finished!')\n",
    "print('Best Test Precision@top1:{:.2f}'.format(best_prec1))\n",
    "writer.add_scalar('Best TOP1', best_prec1, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9a085d-7905-4d95-a92b-dca883df4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Test files loading\n",
      "\n",
      "split train users: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test files loaded ......\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(load_data(training=False), batch_size=batch_size, shuffle=False)  # ,prefetch_factor=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2253928-e81e-4878-b0a0-09cde7302ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (model): Sequential(\n",
      "    (0): GConv(3, 10, kernel_size=(4, 5, 5), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GConv(10, 20, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): GConv(20, 40, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): GConv(40, 80, kernel_size=(4, 5, 5), stride=(2, 2), bias=False)\n",
      "    (12): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=80, out_features=1024, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=450, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f947a0c3490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "print(model)\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "##### REGISTER HOOK\n",
    "\n",
    "model.fc1.register_forward_hook(get_features('feats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f1841c-fd4b-4c4e-b867-77a297778675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATS = []\n",
    "GT = []\n",
    "features = {}\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, img in enumerate(test_loader):\n",
    "            rbn = img[0].to(device, dtype=torch.float)\n",
    "            label = img[1].to(device)\n",
    "\n",
    "            output = model(rbn)\n",
    "            FEATS.append(features['feats'].cpu().numpy())\n",
    "            GT.append(img[1].numpy())\n",
    "\n",
    "  \n",
    "    return acc.avg\n",
    "\n",
    "test()\n",
    "##### INSPECT FEATURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021b1964-473b-4444-b003-4fcf3cd1242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- feats shape: (600, 1024)\n",
      "- GT shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FEATS = np.concatenate(FEATS)\n",
    "GT = np.concatenate(GT)\n",
    "\n",
    "print('- feats shape:', FEATS.shape)\n",
    "print('- GT shape:', GT.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbc60cae-2740-45df-9277-817c10f4fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:05<00:00, 109.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cossim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "pred_scores = []\n",
    "gt_label = []\n",
    "\n",
    "for i in tqdm.tqdm(range(600)):\n",
    "    for j in range(i+1,600):\n",
    "        # pred_scores.append(final[i,j].detach().cpu().numpy())\n",
    "        pred_scores.append(cossim(FEATS[i,:],FEATS[j,:]))\n",
    "        gt_label.append(i//12 == j//12)\n",
    "        \n",
    "\n",
    "# for i in tqdm.tqdm(range(600)):\n",
    "#         # pred_scores.append(final[i,j].detach().cpu().numpy())\n",
    "#         pred_scores.append(cossim(FEATS[i,:],FEATS[]))\n",
    "#         # gt_label.append(i//12 == j//12)\n",
    "pred_scores = np.array(pred_scores)\n",
    "gt_label = np.array(gt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70fbcf98-18e0-4fda-8bfd-53925629bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "/root/miniconda3/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Density')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Gen = pred_scores[gt_label]\n",
    "Imp = pred_scores[gt_label==False]\n",
    "Imp = Imp[np.random.permutation(len(Imp))[:len(Gen)]]\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.distplot(Gen,  kde=False, label='Gen')\n",
    "# df =gapminder[gapminder.continent == 'Americas']\n",
    "sns.distplot(Imp,  kde=False,label='Imp')\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Life Expectancy of Two Continents')\n",
    "plt.xlabel('Life Exp (years)')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9673f170-9bc8-499b-a6c2-29209e84ad25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equal error rate is 0.037236\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "\"\"\"\n",
    "Python compute equal error rate (eer)\n",
    "ONLY tested on binary classification\n",
    "\n",
    ":param label: ground-truth label, should be a 1-d list or np.array, each element represents the ground-truth label of one sample\n",
    ":param pred: model prediction, should be a 1-d list or np.array, each element represents the model prediction of one sample\n",
    ":param positive_label: the class that is viewed as positive class when computing EER\n",
    ":return: equal error rate (EER)\n",
    "\"\"\"\n",
    "def compute_eer(label, pred, positive_label=1):\n",
    "    # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)\n",
    "    fpr, tpr, threshold = sklearn.metrics.roc_curve(label, pred)#, positive_label\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # the threshold of fnr == fpr\n",
    "    eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "    eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # return the mean of eer from fpr and from fnr\n",
    "    eer = (eer_1 + eer_2) / 2\n",
    "    return eer\n",
    "\n",
    "eer = compute_eer(gt_label, pred_scores)\n",
    "print('The equal error rate is {:.6f}'.format(eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3bd27-046c-42d5-a20d-07a9a4343902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
