{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c05f0b-acea-431b-8565-4dbf8ecfcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.nn.modules.conv import _ConvNd\n",
    "from torch.autograd.function import once_differentiable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4cfea-b37d-4d2c-bca9-551beb9e9396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9ef230-ce2d-4cb9-a156-69ea583c05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from gcn.layers import GConv\n",
    "from torchvision import datasets, models, transforms\n",
    "class PositionEncodingSine(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a sinusoidal position encoding that generalized to 2-dimensional images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, max_shape=(256, 256), temp_bug_fix=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_shape (tuple): for 1/8 featmap, the max length of 256 corresponds to 2048 pixels\n",
    "            temp_bug_fix (bool): As noted in this [issue](https://github.com/zju3dv/LoFTR/issues/41),\n",
    "                the original implementation of LoFTR includes a bug in the pos-enc impl, which has little impact\n",
    "                on the final performance. For now, we keep both impls for backward compatability.\n",
    "                We will remove the buggy impl after re-training all variants of our released models.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros((d_model, *max_shape))\n",
    "        y_position = torch.ones(max_shape).cumsum(0).float().unsqueeze(0)\n",
    "        x_position = torch.ones(max_shape).cumsum(1).float().unsqueeze(0)\n",
    "        if temp_bug_fix:\n",
    "            div_term = torch.exp(torch.arange(0, d_model//2, 2).float() * (-math.log(10000.0) / (d_model//2)))\n",
    "        else:  # a buggy implementation (for backward compatability only)\n",
    "            div_term = torch.exp(torch.arange(0, d_model//2, 2).float() * (-math.log(10000.0) / d_model//2))\n",
    "        div_term = div_term[:, None, None]  # [C//4, 1, 1]\n",
    "        pe[0::4, :, :] = torch.sin(x_position * div_term)\n",
    "        pe[1::4, :, :] = torch.cos(x_position * div_term)\n",
    "        pe[2::4, :, :] = torch.sin(y_position * div_term)\n",
    "        pe[3::4, :, :] = torch.cos(y_position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)  # [1, C, H, W]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [N, C, H, W]\n",
    "        \"\"\"\n",
    "#         print(self.pe[:, :, :x.size(2), :x.size(3)].size())\n",
    "#         print(x.size())\n",
    "        return x + self.pe[:, :, :x.size(2), :x.size(3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0522a923-40be-4f07-8ad1-68461d649093",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_277996/3570500984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pos_encoding = PositionEncodingSine(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             temp_bug_fix=False)\n",
      "\u001b[0;32m/tmp/ipykernel_277996/4012421723.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, max_shape, temp_bug_fix)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a buggy implementation (for backward compatability only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv_term\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [C//4, 1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_position\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiv_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "pos_encoding = PositionEncodingSine(\n",
    "            5,\n",
    "            temp_bug_fix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ad0a5-b68c-407e-b3d9-077e09d687b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15619f00-7029-4d4a-abba-07fd01d70c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGaborFilterBank(nScale, M, h, w):\n",
    "    Kmax = math.pi / 2\n",
    "    f = math.sqrt(2)\n",
    "    sigma = math.pi\n",
    "    sqsigma = sigma ** 2\n",
    "    postmean = math.exp(-sqsigma / 2)\n",
    "    if h != 1:\n",
    "        gfilter_real = torch.zeros(M, h, w)\n",
    "        for i in range(M):\n",
    "            theta = i / M * math.pi\n",
    "            k = Kmax / f ** (nScale - 1)\n",
    "            xymax = -1e309\n",
    "            xymin = 1e309\n",
    "            for y in range(h):\n",
    "                for x in range(w):\n",
    "                    y1 = y + 1 - ((h + 1) / 2)\n",
    "                    x1 = x + 1 - ((w + 1) / 2)\n",
    "                    tmp1 = math.exp(-(k * k * (x1 * x1 + y1 * y1) / (2 * sqsigma)))\n",
    "                    tmp2 = math.cos(k * math.cos(theta) * x1 + k * math.sin(theta) * y1) - postmean # For real part\n",
    "                    # tmp3 = math.sin(k*math.cos(theta)*x1+k*math.sin(theta)*y1) # For imaginary part\n",
    "                    gfilter_real[i][y][x] = k * k * tmp1 * tmp2 / sqsigma\t\t\t\n",
    "                    xymax = max(xymax, gfilter_real[i][y][x])\n",
    "                    xymin = min(xymin, gfilter_real[i][y][x])\n",
    "            gfilter_real[i] = (gfilter_real[i] - xymin) / (xymax - xymin)\n",
    "    else:\n",
    "        gfilter_real = torch.ones(M, h, w)\n",
    "    return gfilter_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a6dc37-6c6c-438e-b015-064e059702a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = getGaborFilterBank(3,5,23,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0e903c-a6de-438d-9585-fd73842d2d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3807, 0.3809, 0.3817,  ..., 0.3817, 0.3809, 0.3807],\n",
       "         [0.3805, 0.3809, 0.3825,  ..., 0.3825, 0.3809, 0.3805],\n",
       "         [0.3801, 0.3809, 0.3837,  ..., 0.3837, 0.3809, 0.3801],\n",
       "         ...,\n",
       "         [0.3801, 0.3809, 0.3837,  ..., 0.3837, 0.3809, 0.3801],\n",
       "         [0.3805, 0.3809, 0.3825,  ..., 0.3825, 0.3809, 0.3805],\n",
       "         [0.3807, 0.3809, 0.3817,  ..., 0.3817, 0.3809, 0.3807]],\n",
       "\n",
       "        [[0.3918, 0.3918, 0.3913,  ..., 0.3924, 0.3917, 0.3914],\n",
       "         [0.3918, 0.3915, 0.3902,  ..., 0.3925, 0.3913, 0.3911],\n",
       "         [0.3917, 0.3905, 0.3880,  ..., 0.3915, 0.3902, 0.3904],\n",
       "         ...,\n",
       "         [0.3904, 0.3902, 0.3915,  ..., 0.3880, 0.3905, 0.3917],\n",
       "         [0.3911, 0.3913, 0.3925,  ..., 0.3902, 0.3915, 0.3918],\n",
       "         [0.3914, 0.3917, 0.3924,  ..., 0.3913, 0.3918, 0.3918]],\n",
       "\n",
       "        [[0.3822, 0.3820, 0.3816,  ..., 0.3833, 0.3828, 0.3825],\n",
       "         [0.3818, 0.3812, 0.3801,  ..., 0.3834, 0.3826, 0.3823],\n",
       "         [0.3811, 0.3801, 0.3788,  ..., 0.3815, 0.3813, 0.3815],\n",
       "         ...,\n",
       "         [0.3815, 0.3813, 0.3815,  ..., 0.3788, 0.3801, 0.3811],\n",
       "         [0.3823, 0.3826, 0.3834,  ..., 0.3801, 0.3812, 0.3818],\n",
       "         [0.3825, 0.3828, 0.3833,  ..., 0.3816, 0.3820, 0.3822]],\n",
       "\n",
       "        [[0.3825, 0.3828, 0.3833,  ..., 0.3816, 0.3820, 0.3822],\n",
       "         [0.3823, 0.3826, 0.3834,  ..., 0.3801, 0.3812, 0.3818],\n",
       "         [0.3815, 0.3813, 0.3815,  ..., 0.3788, 0.3801, 0.3811],\n",
       "         ...,\n",
       "         [0.3811, 0.3801, 0.3788,  ..., 0.3815, 0.3813, 0.3815],\n",
       "         [0.3818, 0.3812, 0.3801,  ..., 0.3834, 0.3826, 0.3823],\n",
       "         [0.3822, 0.3820, 0.3816,  ..., 0.3833, 0.3828, 0.3825]],\n",
       "\n",
       "        [[0.3914, 0.3917, 0.3924,  ..., 0.3913, 0.3918, 0.3918],\n",
       "         [0.3911, 0.3913, 0.3925,  ..., 0.3902, 0.3915, 0.3918],\n",
       "         [0.3904, 0.3902, 0.3915,  ..., 0.3880, 0.3905, 0.3917],\n",
       "         ...,\n",
       "         [0.3917, 0.3905, 0.3880,  ..., 0.3915, 0.3902, 0.3904],\n",
       "         [0.3918, 0.3915, 0.3902,  ..., 0.3925, 0.3913, 0.3911],\n",
       "         [0.3918, 0.3918, 0.3913,  ..., 0.3924, 0.3917, 0.3914]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7c2f2-12eb-49d1-8389-4ba339b650bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8011d-640b-43a0-a16c-1c0c33316f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c28d5-3e28-49bd-824a-b1956b0896a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52009426-1a90-49a2-a765-13c9c06e8911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--euclidean | --similarity | --affine | --projective]\n",
      "                             [--grid GRID GRID] [--stop STOP]\n",
      "                             [--inset FRAME | --crop FRAME FRAME | --bounds FRAME FRAME FRAME FRAME]\n",
      "                             [--noise NOISE] [--path PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\HASEE\\AppData\\Roaming\\jupyter\\runtime\\kernel-a69a8a00-94bc-48bd-be26-8eeb5c2003e0.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Dummy\n",
    "The dummy head alignment example from [1].\n",
    "This loads 100 photographed dummy head images at various angles and\n",
    "illuminations, and aligns them with a choice of similarity, affine, or\n",
    "projective transformations.\n",
    "It does not yet implement the paper's quality/success measure (based\n",
    "on transformed eye distances).\n",
    ".. [1] Y. Peng, A. Ganesh, J. Wright, W. Xu, Y. Ma, \"Robust Alignment by\n",
    "   Sparse and Low-rank Decomposition for Linearly Correlated Images\",\n",
    "   IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 2011\n",
    "\"\"\"\n",
    "import os\n",
    "import rasl\n",
    "\n",
    "# args, unknown = parser.parse_known_args()\n",
    "\n",
    "dummy_dir = './dataset/Casia_M/casia_460/'\n",
    "rasl.application.demo_cmd(\n",
    "    description=\"Align dummy images using RASL\",\n",
    "    path=dummy_dir, frame=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7f78c-6124-4b35-ac20-f71085550ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a15db8b-a233-4a09-a28f-f0b6e825d8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[0.4472136  0.89442719]\n",
      " [0.6        0.8       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "A = np.random.randn(4,4)*10\n",
    "A = np.array([[1,2],[3,4]])\n",
    "\n",
    "print(A)\n",
    "# print(normalized(A,0))\n",
    "print(normalized(A,1))# ok verified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "ailab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
