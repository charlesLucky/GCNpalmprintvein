{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c05f0b-acea-431b-8565-4dbf8ecfcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.nn.modules.conv import _ConvNd\n",
    "from torch.autograd.function import once_differentiable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4cfea-b37d-4d2c-bca9-551beb9e9396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9ef230-ce2d-4cb9-a156-69ea583c05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from gcn.layers import GConv\n",
    "from torchvision import datasets, models, transforms\n",
    "class PositionEncodingSine(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a sinusoidal position encoding that generalized to 2-dimensional images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, max_shape=(256, 256), temp_bug_fix=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_shape (tuple): for 1/8 featmap, the max length of 256 corresponds to 2048 pixels\n",
    "            temp_bug_fix (bool): As noted in this [issue](https://github.com/zju3dv/LoFTR/issues/41),\n",
    "                the original implementation of LoFTR includes a bug in the pos-enc impl, which has little impact\n",
    "                on the final performance. For now, we keep both impls for backward compatability.\n",
    "                We will remove the buggy impl after re-training all variants of our released models.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros((d_model, *max_shape))\n",
    "        y_position = torch.ones(max_shape).cumsum(0).float().unsqueeze(0)\n",
    "        x_position = torch.ones(max_shape).cumsum(1).float().unsqueeze(0)\n",
    "        if temp_bug_fix:\n",
    "            div_term = torch.exp(torch.arange(0, d_model//2, 2).float() * (-math.log(10000.0) / (d_model//2)))\n",
    "        else:  # a buggy implementation (for backward compatability only)\n",
    "            div_term = torch.exp(torch.arange(0, d_model//2, 2).float() * (-math.log(10000.0) / d_model//2))\n",
    "        div_term = div_term[:, None, None]  # [C//4, 1, 1]\n",
    "        pe[0::4, :, :] = torch.sin(x_position * div_term)\n",
    "        pe[1::4, :, :] = torch.cos(x_position * div_term)\n",
    "        pe[2::4, :, :] = torch.sin(y_position * div_term)\n",
    "        pe[3::4, :, :] = torch.cos(y_position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)  # [1, C, H, W]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [N, C, H, W]\n",
    "        \"\"\"\n",
    "#         print(self.pe[:, :, :x.size(2), :x.size(3)].size())\n",
    "#         print(x.size())\n",
    "        return x + self.pe[:, :, :x.size(2), :x.size(3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0522a923-40be-4f07-8ad1-68461d649093",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_277996/3570500984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pos_encoding = PositionEncodingSine(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             temp_bug_fix=False)\n",
      "\u001b[0;32m/tmp/ipykernel_277996/4012421723.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, max_shape, temp_bug_fix)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a buggy implementation (for backward compatability only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv_term\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [C//4, 1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_position\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiv_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "pos_encoding = PositionEncodingSine(\n",
    "            5,\n",
    "            temp_bug_fix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ad0a5-b68c-407e-b3d9-077e09d687b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15619f00-7029-4d4a-abba-07fd01d70c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGaborFilterBank(nScale, M, h, w):\n",
    "    Kmax = math.pi / 2\n",
    "    f = math.sqrt(2)\n",
    "    sigma = math.pi\n",
    "    sqsigma = sigma ** 2\n",
    "    postmean = math.exp(-sqsigma / 2)\n",
    "    if h != 1:\n",
    "        gfilter_real = torch.zeros(M, h, w)\n",
    "        for i in range(M):\n",
    "            theta = i / M * math.pi\n",
    "            k = Kmax / f ** (nScale - 1)\n",
    "            xymax = -1e309\n",
    "            xymin = 1e309\n",
    "            for y in range(h):\n",
    "                for x in range(w):\n",
    "                    y1 = y + 1 - ((h + 1) / 2)\n",
    "                    x1 = x + 1 - ((w + 1) / 2)\n",
    "                    tmp1 = math.exp(-(k * k * (x1 * x1 + y1 * y1) / (2 * sqsigma)))\n",
    "                    tmp2 = math.cos(k * math.cos(theta) * x1 + k * math.sin(theta) * y1) - postmean # For real part\n",
    "                    # tmp3 = math.sin(k*math.cos(theta)*x1+k*math.sin(theta)*y1) # For imaginary part\n",
    "                    gfilter_real[i][y][x] = k * k * tmp1 * tmp2 / sqsigma\t\t\t\n",
    "                    xymax = max(xymax, gfilter_real[i][y][x])\n",
    "                    xymin = min(xymin, gfilter_real[i][y][x])\n",
    "            gfilter_real[i] = (gfilter_real[i] - xymin) / (xymax - xymin)\n",
    "    else:\n",
    "        gfilter_real = torch.ones(M, h, w)\n",
    "    return gfilter_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a6dc37-6c6c-438e-b015-064e059702a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = getGaborFilterBank(3,5,23,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0e903c-a6de-438d-9585-fd73842d2d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3807, 0.3809, 0.3817,  ..., 0.3817, 0.3809, 0.3807],\n",
       "         [0.3805, 0.3809, 0.3825,  ..., 0.3825, 0.3809, 0.3805],\n",
       "         [0.3801, 0.3809, 0.3837,  ..., 0.3837, 0.3809, 0.3801],\n",
       "         ...,\n",
       "         [0.3801, 0.3809, 0.3837,  ..., 0.3837, 0.3809, 0.3801],\n",
       "         [0.3805, 0.3809, 0.3825,  ..., 0.3825, 0.3809, 0.3805],\n",
       "         [0.3807, 0.3809, 0.3817,  ..., 0.3817, 0.3809, 0.3807]],\n",
       "\n",
       "        [[0.3918, 0.3918, 0.3913,  ..., 0.3924, 0.3917, 0.3914],\n",
       "         [0.3918, 0.3915, 0.3902,  ..., 0.3925, 0.3913, 0.3911],\n",
       "         [0.3917, 0.3905, 0.3880,  ..., 0.3915, 0.3902, 0.3904],\n",
       "         ...,\n",
       "         [0.3904, 0.3902, 0.3915,  ..., 0.3880, 0.3905, 0.3917],\n",
       "         [0.3911, 0.3913, 0.3925,  ..., 0.3902, 0.3915, 0.3918],\n",
       "         [0.3914, 0.3917, 0.3924,  ..., 0.3913, 0.3918, 0.3918]],\n",
       "\n",
       "        [[0.3822, 0.3820, 0.3816,  ..., 0.3833, 0.3828, 0.3825],\n",
       "         [0.3818, 0.3812, 0.3801,  ..., 0.3834, 0.3826, 0.3823],\n",
       "         [0.3811, 0.3801, 0.3788,  ..., 0.3815, 0.3813, 0.3815],\n",
       "         ...,\n",
       "         [0.3815, 0.3813, 0.3815,  ..., 0.3788, 0.3801, 0.3811],\n",
       "         [0.3823, 0.3826, 0.3834,  ..., 0.3801, 0.3812, 0.3818],\n",
       "         [0.3825, 0.3828, 0.3833,  ..., 0.3816, 0.3820, 0.3822]],\n",
       "\n",
       "        [[0.3825, 0.3828, 0.3833,  ..., 0.3816, 0.3820, 0.3822],\n",
       "         [0.3823, 0.3826, 0.3834,  ..., 0.3801, 0.3812, 0.3818],\n",
       "         [0.3815, 0.3813, 0.3815,  ..., 0.3788, 0.3801, 0.3811],\n",
       "         ...,\n",
       "         [0.3811, 0.3801, 0.3788,  ..., 0.3815, 0.3813, 0.3815],\n",
       "         [0.3818, 0.3812, 0.3801,  ..., 0.3834, 0.3826, 0.3823],\n",
       "         [0.3822, 0.3820, 0.3816,  ..., 0.3833, 0.3828, 0.3825]],\n",
       "\n",
       "        [[0.3914, 0.3917, 0.3924,  ..., 0.3913, 0.3918, 0.3918],\n",
       "         [0.3911, 0.3913, 0.3925,  ..., 0.3902, 0.3915, 0.3918],\n",
       "         [0.3904, 0.3902, 0.3915,  ..., 0.3880, 0.3905, 0.3917],\n",
       "         ...,\n",
       "         [0.3917, 0.3905, 0.3880,  ..., 0.3915, 0.3902, 0.3904],\n",
       "         [0.3918, 0.3915, 0.3902,  ..., 0.3925, 0.3913, 0.3911],\n",
       "         [0.3918, 0.3918, 0.3913,  ..., 0.3924, 0.3917, 0.3914]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7c2f2-12eb-49d1-8389-4ba339b650bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8011d-640b-43a0-a16c-1c0c33316f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c28d5-3e28-49bd-824a-b1956b0896a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52009426-1a90-49a2-a765-13c9c06e8911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--euclidean | --similarity | --affine | --projective]\n",
      "                             [--grid GRID GRID] [--stop STOP]\n",
      "                             [--inset FRAME | --crop FRAME FRAME | --bounds FRAME FRAME FRAME FRAME]\n",
      "                             [--noise NOISE] [--path PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\HASEE\\AppData\\Roaming\\jupyter\\runtime\\kernel-a69a8a00-94bc-48bd-be26-8eeb5c2003e0.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Dummy\n",
    "The dummy head alignment example from [1].\n",
    "This loads 100 photographed dummy head images at various angles and\n",
    "illuminations, and aligns them with a choice of similarity, affine, or\n",
    "projective transformations.\n",
    "It does not yet implement the paper's quality/success measure (based\n",
    "on transformed eye distances).\n",
    ".. [1] Y. Peng, A. Ganesh, J. Wright, W. Xu, Y. Ma, \"Robust Alignment by\n",
    "   Sparse and Low-rank Decomposition for Linearly Correlated Images\",\n",
    "   IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 2011\n",
    "\"\"\"\n",
    "import os\n",
    "import rasl\n",
    "\n",
    "# args, unknown = parser.parse_known_args()\n",
    "\n",
    "dummy_dir = './dataset/Casia_M/casia_460/'\n",
    "rasl.application.demo_cmd(\n",
    "    description=\"Align dummy images using RASL\",\n",
    "    path=dummy_dir, frame=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7f78c-6124-4b35-ac20-f71085550ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a15db8b-a233-4a09-a28f-f0b6e825d8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[0.4472136  0.89442719]\n",
      " [0.6        0.8       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "A = np.random.randn(4,4)*10\n",
    "A = np.array([[1,2],[3,4]])\n",
    "\n",
    "print(A)\n",
    "# print(normalized(A,0))\n",
    "print(normalized(A,1))# ok verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904b685-2950-4d35-b404-ae604cb2891b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea0e79c-0b61-4716-809e-4d2f4a82ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import torch.nn.functional as F\n",
    "from utils import accuracy, AverageMeter, save_checkpoint, visualize_graph, get_parameters_size\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# del test_loader\n",
    "import tqdm\n",
    "# test_loader\n",
    "\n",
    "from loss import CSQLoss\n",
    "from DsZoo import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b959505-176b-46dd-8905-6481273a7733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Train files loading\n",
      "\n",
      "split train users: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:03<00:00, 62.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train files loaded ......\n",
      "\n",
      "\n",
      "...... Test files loading\n",
      "\n",
      "split train users: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 102.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test files loaded ......\n",
      "\n",
      "800\n",
      "400\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26040/2711624131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ailab\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_config():\n",
    "    config = {\n",
    "        \"lambda\": 0.80,# 0.8 009# 0.3 0085 # 0 011\n",
    "        \"optimizer\": {\"type\": optim.RMSprop, \"optim_params\": {\"lr\": 1e-5, \"weight_decay\": 10 ** -5}},\n",
    "        \"info\": \"[CSQCasiaMGCN1]\",\n",
    "        \"batch_size\": 2,\n",
    "        \"net\": 'GCNhashingOneChannel',\n",
    "        \"dataset\": \"CasiaM\",\n",
    "        \"n_class\":200,# pay attention\n",
    "        \"epoch\": 50,\n",
    "        \"test_map\": 10,\n",
    "        # \"device\":torch.device(\"cpu\"),\n",
    "        \"device\": torch.device(\"cuda:0\"),\n",
    "        \"bit_list\": [1024],\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "config = get_config()\n",
    "train_loader, test_loader, num_train, num_test = get_data(config) \n",
    "for batch_idx, img in enumerate(train_loader):\n",
    "    image = img[0].permute(0, 3, 1, 2).to(device, dtype=torch.float)\n",
    "    label = img[1].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd75b8-0f7b-47df-972a-6794163a44af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "ailab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
